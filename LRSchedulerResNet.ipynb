{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfGrai_Qt7Ny"
      },
      "source": [
        "# import all libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import random_split\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import os\n",
        "import argparse\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgAiImV0uURP"
      },
      "source": [
        "import pickle\n",
        "\n",
        "# Define transforms (keep these - they're still needed!)\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "# Load the saved datasets from pickle files\n",
        "print(\"Loading datasets from pickle files...\")\n",
        "\n",
        "with open('./data/train_dataset.pkl', 'rb') as f:\n",
        "    trainset = pickle.load(f)\n",
        "\n",
        "with open('./data/val_dataset.pkl', 'rb') as f:\n",
        "    valset = pickle.load(f)\n",
        "\n",
        "# Don't load test for Section 4 (not needed)\n",
        "# with open('./data/test_dataset.pkl', 'rb') as f:\n",
        "#     testset = pickle.load(f)\n",
        "\n",
        "print(f\"âœ… Loaded! Train={len(trainset)}, Val={len(valset)}\")\n",
        "\n",
        "# Create DataLoaders\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "valloader = torch.utils.data.DataLoader(\n",
        "    valset, batch_size=128, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
        "           'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9e4QhB5B89H"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hldipDVsv-Jt"
      },
      "source": [
        "# Training\n",
        "def train(epoch, net, criterion, trainloader, scheduler=None):\n",
        "    device = 'cuda'\n",
        "    print('\\nEpoch: %d' % epoch)\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "        if (batch_idx+1) % 50 == 0:\n",
        "          print(\"iteration : %3d, loss : %0.4f, accuracy : %2.2f\" % (batch_idx+1, train_loss/(batch_idx+1), 100.*correct/total))\n",
        "\n",
        "    if scheduler is not None:\n",
        "        scheduler.step()\n",
        "    return train_loss/(batch_idx+1), 100.*correct/total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgyCI0U08i2h"
      },
      "source": [
        "Test performance on the test set. Note the use of `torch.inference_mode()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkooK-hQu4a6"
      },
      "source": [
        "def test(epoch, net, criterion, testloader):\n",
        "    device = 'cuda'\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.inference_mode():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    return test_loss/(batch_idx+1), 100.*correct/total\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEj8J7xqwAxD"
      },
      "source": [
        "def save_checkpoint(net, acc, epoch):\n",
        "    # Save checkpoint.\n",
        "    print('Saving..')\n",
        "    state = {\n",
        "        'net': net.state_dict(),\n",
        "        'acc': acc,\n",
        "        'epoch': epoch,\n",
        "    }\n",
        "    if not os.path.isdir('checkpoint'):\n",
        "        os.mkdir('checkpoint')\n",
        "    torch.save(state, './checkpoint/ckpt.pth')\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlCAjBEWwXNo"
      },
      "source": [
        "# defining resnet models\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
        "                               planes, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        # This is the \"stem\"\n",
        "        # For CIFAR (32x32 images), it does not perform downsampling\n",
        "        # It should downsample for ImageNet\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        # four stages with three downsampling\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def ResNet18():\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
        "\n",
        "\n",
        "def ResNet34():\n",
        "    return ResNet(BasicBlock, [3, 4, 6, 3])\n",
        "\n",
        "\n",
        "def ResNet50():\n",
        "    return ResNet(Bottleneck, [3, 4, 6, 3])\n",
        "\n",
        "\n",
        "def ResNet101():\n",
        "    return ResNet(Bottleneck, [3, 4, 23, 3])\n",
        "\n",
        "\n",
        "def ResNet152():\n",
        "    return ResNet(Bottleneck, [3, 8, 36, 3])\n",
        "\n",
        "\n",
        "def test_resnet18():\n",
        "    net = ResNet18()\n",
        "    y = net(torch.randn(1, 3, 32, 32))\n",
        "    print(y.size())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "CrfVayc0LCC5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Learning Rate Schedule\n",
        "\n",
        "Chosen LR from prev experiment = 0.01\n",
        "\n",
        "2 experiments: constant LR & Cosine Annealing\n",
        "\n",
        "Epochs = 300\n",
        "\n",
        "Other hyperparameters unchanged"
      ],
      "metadata": {
        "id": "pcOueHiXenry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chosen_LR = 0.01\n",
        "\n",
        "# main body\n",
        "config = {\n",
        "    'lr': chosen_LR,\n",
        "    'momentum': 0.9,\n",
        "}\n"
      ],
      "metadata": {
        "id": "DKbsbBxPf-tO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"Training without CosineAnnealingLR\")\n",
        "print(f\"{'='*60}\\n\")\n",
        "\n",
        "net = ResNet18().to('cuda')\n",
        "criterion = nn.CrossEntropyLoss().to('cuda')\n",
        "optimizer = optim.SGD(net.parameters(), lr=config['lr'],\n",
        "                      momentum=config['momentum'])\n",
        "# Lists to store losses and accuracies\n",
        "train_losses = []\n",
        "train_accs = []\n",
        "val_losses = []\n",
        "val_accs = []\n",
        "\n",
        "for epoch in range(1, 301):\n",
        "    train_loss, train_acc = train(epoch, net, criterion, trainloader)\n",
        "    val_loss, val_acc = test(epoch, net, criterion, valloader)\n",
        "\n",
        "  # Store values\n",
        "    train_losses.append(train_loss)\n",
        "    train_accs.append(train_acc)\n",
        "    val_losses.append(val_loss)\n",
        "    val_accs.append(val_acc)\n",
        "\n",
        "    print((\"Epoch : %3d, training loss : %0.4f, training accuracy : %2.2f, val loss \" + \\\n",
        "          \": %0.4f, val accuracy : %2.2f\") % (epoch, train_loss, train_acc, val_loss, val_acc))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Plot\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Loss plot\n",
        "ax1.plot(range(1, 301), train_losses, 'b-', label='Train', linewidth=2)\n",
        "ax1.plot(range(1, 301), val_losses, 'r-', label='Validation', linewidth=2)\n",
        "ax1.set_xlabel(\"Epoch\", fontsize=12)\n",
        "ax1.set_ylabel(\"Loss\", fontsize=12)\n",
        "ax1.set_title(f\"Loss vs Epochs (no LR scheduler)\", fontsize=14)\n",
        "ax1.legend(fontsize=11)\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Accuracy plot\n",
        "ax2.plot(range(1, 301), train_accs, 'b-', label='Train', linewidth=2)\n",
        "ax2.plot(range(1, 301), val_accs, 'r-', label='Validation', linewidth=2)\n",
        "ax2.set_xlabel(\"Epoch\", fontsize=12)\n",
        "ax2.set_ylabel(\"Accuracy (%)\", fontsize=12)\n",
        "ax2.set_title(f\"Accuracy vs Epochs (no LR scheduler)\", fontsize=14)\n",
        "ax2.legend(fontsize=11)\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(f'section4_noLRScheduler.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Print final results\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"Final Results for no LR scheduler\")\n",
        "print(f\"  Train Loss: {train_losses[-1]:.4f}, Train Acc: {train_accs[-1]:.2f}%\")\n",
        "print(f\"  Val Loss: {val_losses[-1]:.4f}, Val Acc: {val_accs[-1]:.2f}%\")\n",
        "print(f\"{'='*60}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dX2nTMYfngp",
        "outputId": "bd3e0f42-b367-4d79-c667-d7e207da4fd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Training without CosineAnnealingLR\n",
            "============================================================\n",
            "\n",
            "\n",
            "Epoch: 1\n",
            "iteration :  50, loss : 1.9636, accuracy : 27.14\n",
            "iteration : 100, loss : 1.8136, accuracy : 33.05\n",
            "iteration : 150, loss : 1.7141, accuracy : 36.68\n",
            "iteration : 200, loss : 1.6394, accuracy : 39.68\n",
            "iteration : 250, loss : 1.5792, accuracy : 41.92\n",
            "iteration : 300, loss : 1.5253, accuracy : 44.00\n",
            "Epoch :   1, training loss : 1.5133, training accuracy : 44.52, val loss : 1.4061, val accuracy : 50.88\n",
            "\n",
            "Epoch: 2\n",
            "iteration :  50, loss : 1.1677, accuracy : 58.11\n",
            "iteration : 100, loss : 1.1370, accuracy : 59.50\n",
            "iteration : 150, loss : 1.0990, accuracy : 60.80\n",
            "iteration : 200, loss : 1.0828, accuracy : 61.29\n",
            "iteration : 250, loss : 1.0611, accuracy : 62.20\n",
            "iteration : 300, loss : 1.0339, accuracy : 63.25\n",
            "Epoch :   2, training loss : 1.0296, training accuracy : 63.43, val loss : 0.9887, val accuracy : 65.84\n",
            "\n",
            "Epoch: 3\n",
            "iteration :  50, loss : 0.8631, accuracy : 69.05\n",
            "iteration : 100, loss : 0.8566, accuracy : 69.41\n",
            "iteration : 150, loss : 0.8442, accuracy : 70.19\n",
            "iteration : 200, loss : 0.8314, accuracy : 70.75\n",
            "iteration : 250, loss : 0.8151, accuracy : 71.34\n",
            "iteration : 300, loss : 0.8040, accuracy : 71.77\n",
            "Epoch :   3, training loss : 0.8006, training accuracy : 71.89, val loss : 0.7783, val accuracy : 72.37\n",
            "\n",
            "Epoch: 4\n",
            "iteration :  50, loss : 0.6677, accuracy : 76.31\n",
            "iteration : 100, loss : 0.6757, accuracy : 76.12\n",
            "iteration : 150, loss : 0.6807, accuracy : 76.05\n",
            "iteration : 200, loss : 0.6777, accuracy : 76.02\n",
            "iteration : 250, loss : 0.6710, accuracy : 76.35\n",
            "iteration : 300, loss : 0.6694, accuracy : 76.48\n",
            "Epoch :   4, training loss : 0.6686, training accuracy : 76.55, val loss : 0.7565, val accuracy : 74.67\n",
            "\n",
            "Epoch: 5\n",
            "iteration :  50, loss : 0.5805, accuracy : 79.47\n",
            "iteration : 100, loss : 0.5938, accuracy : 79.16\n",
            "iteration : 150, loss : 0.5962, accuracy : 79.29\n",
            "iteration : 200, loss : 0.5912, accuracy : 79.36\n",
            "iteration : 250, loss : 0.5835, accuracy : 79.65\n",
            "iteration : 300, loss : 0.5810, accuracy : 79.76\n",
            "Epoch :   5, training loss : 0.5808, training accuracy : 79.76, val loss : 0.7808, val accuracy : 73.77\n",
            "\n",
            "Epoch: 6\n",
            "iteration :  50, loss : 0.5330, accuracy : 81.55\n",
            "iteration : 100, loss : 0.5458, accuracy : 80.99\n",
            "iteration : 150, loss : 0.5359, accuracy : 81.33\n",
            "iteration : 200, loss : 0.5307, accuracy : 81.48\n",
            "iteration : 250, loss : 0.5260, accuracy : 81.75\n",
            "iteration : 300, loss : 0.5228, accuracy : 81.89\n",
            "Epoch :   6, training loss : 0.5199, training accuracy : 82.00, val loss : 0.6727, val accuracy : 77.34\n",
            "\n",
            "Epoch: 7\n",
            "iteration :  50, loss : 0.4946, accuracy : 82.94\n",
            "iteration : 100, loss : 0.4931, accuracy : 82.95\n",
            "iteration : 150, loss : 0.4830, accuracy : 83.37\n",
            "iteration : 200, loss : 0.4765, accuracy : 83.51\n",
            "iteration : 250, loss : 0.4740, accuracy : 83.66\n",
            "iteration : 300, loss : 0.4730, accuracy : 83.66\n",
            "Epoch :   7, training loss : 0.4713, training accuracy : 83.74, val loss : 0.5311, val accuracy : 81.49\n",
            "\n",
            "Epoch: 8\n",
            "iteration :  50, loss : 0.4327, accuracy : 85.27\n",
            "iteration : 100, loss : 0.4230, accuracy : 85.45\n",
            "iteration : 150, loss : 0.4252, accuracy : 85.32\n",
            "iteration : 200, loss : 0.4262, accuracy : 85.38\n",
            "iteration : 250, loss : 0.4287, accuracy : 85.19\n",
            "iteration : 300, loss : 0.4276, accuracy : 85.18\n",
            "Epoch :   8, training loss : 0.4272, training accuracy : 85.20, val loss : 0.6036, val accuracy : 79.87\n",
            "\n",
            "Epoch: 9\n",
            "iteration :  50, loss : 0.3797, accuracy : 86.20\n",
            "iteration : 100, loss : 0.3911, accuracy : 86.05\n",
            "iteration : 150, loss : 0.3916, accuracy : 86.21\n",
            "iteration : 200, loss : 0.3937, accuracy : 86.42\n",
            "iteration : 250, loss : 0.3928, accuracy : 86.44\n",
            "iteration : 300, loss : 0.3954, accuracy : 86.33\n",
            "Epoch :   9, training loss : 0.3936, training accuracy : 86.38, val loss : 0.5303, val accuracy : 82.23\n",
            "\n",
            "Epoch: 10\n",
            "iteration :  50, loss : 0.3514, accuracy : 88.09\n",
            "iteration : 100, loss : 0.3578, accuracy : 87.88\n",
            "iteration : 150, loss : 0.3562, accuracy : 87.89\n",
            "iteration : 200, loss : 0.3532, accuracy : 87.95\n",
            "iteration : 250, loss : 0.3552, accuracy : 87.82\n",
            "iteration : 300, loss : 0.3597, accuracy : 87.60\n",
            "Epoch :  10, training loss : 0.3608, training accuracy : 87.58, val loss : 0.5079, val accuracy : 82.75\n",
            "\n",
            "Epoch: 11\n",
            "iteration :  50, loss : 0.3326, accuracy : 88.27\n",
            "iteration : 100, loss : 0.3310, accuracy : 88.29\n",
            "iteration : 150, loss : 0.3265, accuracy : 88.61\n",
            "iteration : 200, loss : 0.3339, accuracy : 88.40\n",
            "iteration : 250, loss : 0.3350, accuracy : 88.34\n",
            "iteration : 300, loss : 0.3351, accuracy : 88.34\n",
            "Epoch :  11, training loss : 0.3370, training accuracy : 88.23, val loss : 0.4996, val accuracy : 82.97\n",
            "\n",
            "Epoch: 12\n",
            "iteration :  50, loss : 0.3218, accuracy : 88.69\n",
            "iteration : 100, loss : 0.3135, accuracy : 89.02\n",
            "iteration : 150, loss : 0.3134, accuracy : 89.09\n",
            "iteration : 200, loss : 0.3160, accuracy : 89.00\n",
            "iteration : 250, loss : 0.3190, accuracy : 89.00\n",
            "iteration : 300, loss : 0.3169, accuracy : 89.08\n",
            "Epoch :  12, training loss : 0.3171, training accuracy : 89.08, val loss : 0.4818, val accuracy : 84.09\n",
            "\n",
            "Epoch: 13\n",
            "iteration :  50, loss : 0.2861, accuracy : 90.02\n",
            "iteration : 100, loss : 0.2827, accuracy : 90.02\n",
            "iteration : 150, loss : 0.2843, accuracy : 89.99\n",
            "iteration : 200, loss : 0.2913, accuracy : 89.74\n",
            "iteration : 250, loss : 0.2932, accuracy : 89.78\n",
            "iteration : 300, loss : 0.2920, accuracy : 89.88\n",
            "Epoch :  13, training loss : 0.2928, training accuracy : 89.83, val loss : 0.4876, val accuracy : 84.11\n",
            "\n",
            "Epoch: 14\n",
            "iteration :  50, loss : 0.2575, accuracy : 91.19\n",
            "iteration : 100, loss : 0.2508, accuracy : 91.37\n",
            "iteration : 150, loss : 0.2583, accuracy : 91.13\n",
            "iteration : 200, loss : 0.2616, accuracy : 91.01\n",
            "iteration : 250, loss : 0.2636, accuracy : 90.94\n",
            "iteration : 300, loss : 0.2657, accuracy : 90.86\n",
            "Epoch :  14, training loss : 0.2657, training accuracy : 90.83, val loss : 0.4593, val accuracy : 85.40\n",
            "\n",
            "Epoch: 15\n",
            "iteration :  50, loss : 0.2473, accuracy : 91.41\n",
            "iteration : 100, loss : 0.2429, accuracy : 91.66\n",
            "iteration : 150, loss : 0.2473, accuracy : 91.46\n",
            "iteration : 200, loss : 0.2509, accuracy : 91.23\n",
            "iteration : 250, loss : 0.2531, accuracy : 91.15\n",
            "iteration : 300, loss : 0.2573, accuracy : 91.02\n",
            "Epoch :  15, training loss : 0.2585, training accuracy : 90.94, val loss : 0.4388, val accuracy : 85.23\n",
            "\n",
            "Epoch: 16\n",
            "iteration :  50, loss : 0.2274, accuracy : 92.48\n",
            "iteration : 100, loss : 0.2214, accuracy : 92.55\n",
            "iteration : 150, loss : 0.2227, accuracy : 92.45\n",
            "iteration : 200, loss : 0.2265, accuracy : 92.25\n",
            "iteration : 250, loss : 0.2334, accuracy : 92.06\n",
            "iteration : 300, loss : 0.2370, accuracy : 91.90\n",
            "Epoch :  16, training loss : 0.2375, training accuracy : 91.87, val loss : 0.4529, val accuracy : 84.85\n",
            "\n",
            "Epoch: 17\n",
            "iteration :  50, loss : 0.2125, accuracy : 92.42\n",
            "iteration : 100, loss : 0.2173, accuracy : 92.33\n",
            "iteration : 150, loss : 0.2156, accuracy : 92.40\n",
            "iteration : 200, loss : 0.2211, accuracy : 92.25\n",
            "iteration : 250, loss : 0.2217, accuracy : 92.28\n",
            "iteration : 300, loss : 0.2223, accuracy : 92.27\n",
            "Epoch :  17, training loss : 0.2219, training accuracy : 92.28, val loss : 0.4079, val accuracy : 86.87\n",
            "\n",
            "Epoch: 18\n",
            "iteration :  50, loss : 0.1993, accuracy : 92.88\n",
            "iteration : 100, loss : 0.2079, accuracy : 92.73\n",
            "iteration : 150, loss : 0.2091, accuracy : 92.75\n",
            "iteration : 200, loss : 0.2065, accuracy : 92.83\n",
            "iteration : 250, loss : 0.2103, accuracy : 92.71\n",
            "iteration : 300, loss : 0.2115, accuracy : 92.69\n",
            "Epoch :  18, training loss : 0.2127, training accuracy : 92.64, val loss : 0.4078, val accuracy : 86.69\n",
            "\n",
            "Epoch: 19\n",
            "iteration :  50, loss : 0.1839, accuracy : 93.52\n",
            "iteration : 100, loss : 0.1805, accuracy : 93.68\n",
            "iteration : 150, loss : 0.1856, accuracy : 93.41\n",
            "iteration : 200, loss : 0.1901, accuracy : 93.25\n",
            "iteration : 250, loss : 0.1949, accuracy : 93.05\n",
            "iteration : 300, loss : 0.1974, accuracy : 92.95\n",
            "Epoch :  19, training loss : 0.1976, training accuracy : 92.95, val loss : 0.4015, val accuracy : 87.21\n",
            "\n",
            "Epoch: 20\n",
            "iteration :  50, loss : 0.1782, accuracy : 93.67\n",
            "iteration : 100, loss : 0.1747, accuracy : 93.68\n",
            "iteration : 150, loss : 0.1771, accuracy : 93.63\n",
            "iteration : 200, loss : 0.1771, accuracy : 93.64\n",
            "iteration : 250, loss : 0.1814, accuracy : 93.55\n",
            "iteration : 300, loss : 0.1852, accuracy : 93.41\n",
            "Epoch :  20, training loss : 0.1865, training accuracy : 93.37, val loss : 0.4487, val accuracy : 85.93\n",
            "\n",
            "Epoch: 21\n",
            "iteration :  50, loss : 0.1683, accuracy : 94.23\n",
            "iteration : 100, loss : 0.1709, accuracy : 94.13\n",
            "iteration : 150, loss : 0.1758, accuracy : 93.83\n",
            "iteration : 200, loss : 0.1764, accuracy : 93.77\n",
            "iteration : 250, loss : 0.1794, accuracy : 93.63\n",
            "iteration : 300, loss : 0.1793, accuracy : 93.62\n",
            "Epoch :  21, training loss : 0.1788, training accuracy : 93.64, val loss : 0.4805, val accuracy : 85.31\n",
            "\n",
            "Epoch: 22\n",
            "iteration :  50, loss : 0.1536, accuracy : 94.36\n",
            "iteration : 100, loss : 0.1585, accuracy : 94.23\n",
            "iteration : 150, loss : 0.1662, accuracy : 94.07\n",
            "iteration : 200, loss : 0.1679, accuracy : 94.00\n",
            "iteration : 250, loss : 0.1673, accuracy : 94.05\n",
            "iteration : 300, loss : 0.1692, accuracy : 93.98\n",
            "Epoch :  22, training loss : 0.1685, training accuracy : 94.00, val loss : 0.3828, val accuracy : 87.97\n",
            "\n",
            "Epoch: 23\n",
            "iteration :  50, loss : 0.1477, accuracy : 94.38\n",
            "iteration : 100, loss : 0.1441, accuracy : 94.72\n",
            "iteration : 150, loss : 0.1524, accuracy : 94.36\n",
            "iteration : 200, loss : 0.1553, accuracy : 94.24\n",
            "iteration : 250, loss : 0.1574, accuracy : 94.19\n",
            "iteration : 300, loss : 0.1585, accuracy : 94.26\n",
            "Epoch :  23, training loss : 0.1597, training accuracy : 94.22, val loss : 0.4869, val accuracy : 85.63\n",
            "\n",
            "Epoch: 24\n",
            "iteration :  50, loss : 0.1558, accuracy : 94.56\n",
            "iteration : 100, loss : 0.1421, accuracy : 95.23\n",
            "iteration : 150, loss : 0.1464, accuracy : 94.95\n",
            "iteration : 200, loss : 0.1499, accuracy : 94.78\n",
            "iteration : 250, loss : 0.1493, accuracy : 94.80\n",
            "iteration : 300, loss : 0.1501, accuracy : 94.75\n",
            "Epoch :  24, training loss : 0.1510, training accuracy : 94.71, val loss : 0.4278, val accuracy : 87.29\n",
            "\n",
            "Epoch: 25\n",
            "iteration :  50, loss : 0.1316, accuracy : 95.30\n",
            "iteration : 100, loss : 0.1367, accuracy : 94.99\n",
            "iteration : 150, loss : 0.1427, accuracy : 94.83\n",
            "iteration : 200, loss : 0.1440, accuracy : 94.79\n",
            "iteration : 250, loss : 0.1430, accuracy : 94.82\n",
            "iteration : 300, loss : 0.1421, accuracy : 94.84\n",
            "Epoch :  25, training loss : 0.1422, training accuracy : 94.85, val loss : 0.4282, val accuracy : 87.10\n",
            "\n",
            "Epoch: 26\n",
            "iteration :  50, loss : 0.1301, accuracy : 95.39\n",
            "iteration : 100, loss : 0.1245, accuracy : 95.62\n",
            "iteration : 150, loss : 0.1271, accuracy : 95.53\n",
            "iteration : 200, loss : 0.1275, accuracy : 95.51\n",
            "iteration : 250, loss : 0.1287, accuracy : 95.49\n",
            "iteration : 300, loss : 0.1292, accuracy : 95.44\n",
            "Epoch :  26, training loss : 0.1297, training accuracy : 95.44, val loss : 0.4581, val accuracy : 87.20\n",
            "\n",
            "Epoch: 27\n",
            "iteration :  50, loss : 0.1212, accuracy : 95.77\n",
            "iteration : 100, loss : 0.1171, accuracy : 95.83\n",
            "iteration : 150, loss : 0.1202, accuracy : 95.70\n",
            "iteration : 200, loss : 0.1247, accuracy : 95.55\n",
            "iteration : 250, loss : 0.1278, accuracy : 95.40\n",
            "iteration : 300, loss : 0.1257, accuracy : 95.51\n",
            "Epoch :  27, training loss : 0.1258, training accuracy : 95.52, val loss : 0.3896, val accuracy : 88.67\n",
            "\n",
            "Epoch: 28\n",
            "iteration :  50, loss : 0.1126, accuracy : 96.14\n",
            "iteration : 100, loss : 0.1109, accuracy : 96.02\n",
            "iteration : 150, loss : 0.1082, accuracy : 96.22\n",
            "iteration : 200, loss : 0.1088, accuracy : 96.17\n",
            "iteration : 250, loss : 0.1089, accuracy : 96.16\n",
            "iteration : 300, loss : 0.1100, accuracy : 96.13\n",
            "Epoch :  28, training loss : 0.1103, training accuracy : 96.12, val loss : 0.4594, val accuracy : 87.33\n",
            "\n",
            "Epoch: 29\n",
            "iteration :  50, loss : 0.0996, accuracy : 96.50\n",
            "iteration : 100, loss : 0.1097, accuracy : 96.12\n",
            "iteration : 150, loss : 0.1092, accuracy : 96.14\n",
            "iteration : 200, loss : 0.1125, accuracy : 96.03\n",
            "iteration : 250, loss : 0.1137, accuracy : 95.92\n",
            "iteration : 300, loss : 0.1137, accuracy : 95.88\n",
            "Epoch :  29, training loss : 0.1143, training accuracy : 95.87, val loss : 0.4349, val accuracy : 88.11\n",
            "\n",
            "Epoch: 30\n",
            "iteration :  50, loss : 0.1007, accuracy : 96.34\n",
            "iteration : 100, loss : 0.0973, accuracy : 96.55\n",
            "iteration : 150, loss : 0.0978, accuracy : 96.54\n",
            "iteration : 200, loss : 0.0972, accuracy : 96.55\n",
            "iteration : 250, loss : 0.0986, accuracy : 96.47\n",
            "iteration : 300, loss : 0.1005, accuracy : 96.37\n",
            "Epoch :  30, training loss : 0.0998, training accuracy : 96.39, val loss : 0.3923, val accuracy : 88.81\n",
            "\n",
            "Epoch: 31\n",
            "iteration :  50, loss : 0.0958, accuracy : 96.67\n",
            "iteration : 100, loss : 0.0927, accuracy : 96.69\n",
            "iteration : 150, loss : 0.0963, accuracy : 96.49\n",
            "iteration : 200, loss : 0.0987, accuracy : 96.42\n",
            "iteration : 250, loss : 0.0978, accuracy : 96.45\n",
            "iteration : 300, loss : 0.0983, accuracy : 96.43\n",
            "Epoch :  31, training loss : 0.0990, training accuracy : 96.42, val loss : 0.4356, val accuracy : 87.99\n",
            "\n",
            "Epoch: 32\n",
            "iteration :  50, loss : 0.0982, accuracy : 96.55\n",
            "iteration : 100, loss : 0.0959, accuracy : 96.74\n",
            "iteration : 150, loss : 0.0945, accuracy : 96.72\n",
            "iteration : 200, loss : 0.0958, accuracy : 96.67\n",
            "iteration : 250, loss : 0.0971, accuracy : 96.62\n",
            "iteration : 300, loss : 0.0985, accuracy : 96.54\n",
            "Epoch :  32, training loss : 0.0988, training accuracy : 96.53, val loss : 0.4300, val accuracy : 88.01\n",
            "\n",
            "Epoch: 33\n",
            "iteration :  50, loss : 0.0827, accuracy : 97.23\n",
            "iteration : 100, loss : 0.0800, accuracy : 97.18\n",
            "iteration : 150, loss : 0.0812, accuracy : 97.11\n",
            "iteration : 200, loss : 0.0848, accuracy : 96.97\n",
            "iteration : 250, loss : 0.0883, accuracy : 96.83\n",
            "iteration : 300, loss : 0.0911, accuracy : 96.69\n",
            "Epoch :  33, training loss : 0.0909, training accuracy : 96.68, val loss : 0.4032, val accuracy : 88.76\n",
            "\n",
            "Epoch: 34\n",
            "iteration :  50, loss : 0.0935, accuracy : 96.62\n",
            "iteration : 100, loss : 0.0885, accuracy : 96.88\n",
            "iteration : 150, loss : 0.0857, accuracy : 97.02\n",
            "iteration : 200, loss : 0.0862, accuracy : 96.97\n",
            "iteration : 250, loss : 0.0879, accuracy : 96.90\n",
            "iteration : 300, loss : 0.0904, accuracy : 96.78\n",
            "Epoch :  34, training loss : 0.0907, training accuracy : 96.76, val loss : 0.4323, val accuracy : 88.13\n",
            "\n",
            "Epoch: 35\n",
            "iteration :  50, loss : 0.0842, accuracy : 97.09\n",
            "iteration : 100, loss : 0.0905, accuracy : 96.95\n",
            "iteration : 150, loss : 0.0904, accuracy : 96.90\n",
            "iteration : 200, loss : 0.0884, accuracy : 96.94\n",
            "iteration : 250, loss : 0.0865, accuracy : 97.00\n",
            "iteration : 300, loss : 0.0887, accuracy : 96.89\n",
            "Epoch :  35, training loss : 0.0887, training accuracy : 96.88, val loss : 0.4200, val accuracy : 88.98\n",
            "\n",
            "Epoch: 36\n",
            "iteration :  50, loss : 0.0687, accuracy : 97.55\n",
            "iteration : 100, loss : 0.0711, accuracy : 97.49\n",
            "iteration : 150, loss : 0.0726, accuracy : 97.38\n",
            "iteration : 200, loss : 0.0704, accuracy : 97.47\n",
            "iteration : 250, loss : 0.0702, accuracy : 97.49\n",
            "iteration : 300, loss : 0.0725, accuracy : 97.39\n",
            "Epoch :  36, training loss : 0.0732, training accuracy : 97.36, val loss : 0.3834, val accuracy : 89.10\n",
            "\n",
            "Epoch: 37\n",
            "iteration :  50, loss : 0.0708, accuracy : 97.50\n",
            "iteration : 100, loss : 0.0701, accuracy : 97.55\n",
            "iteration : 150, loss : 0.0646, accuracy : 97.73\n",
            "iteration : 200, loss : 0.0672, accuracy : 97.65\n",
            "iteration : 250, loss : 0.0706, accuracy : 97.53\n",
            "iteration : 300, loss : 0.0731, accuracy : 97.45\n",
            "Epoch :  37, training loss : 0.0738, training accuracy : 97.42, val loss : 0.4080, val accuracy : 89.11\n",
            "\n",
            "Epoch: 38\n",
            "iteration :  50, loss : 0.0742, accuracy : 97.42\n",
            "iteration : 100, loss : 0.0734, accuracy : 97.38\n",
            "iteration : 150, loss : 0.0706, accuracy : 97.43\n",
            "iteration : 200, loss : 0.0679, accuracy : 97.52\n",
            "iteration : 250, loss : 0.0698, accuracy : 97.47\n",
            "iteration : 300, loss : 0.0714, accuracy : 97.45\n",
            "Epoch :  38, training loss : 0.0708, training accuracy : 97.47, val loss : 0.4126, val accuracy : 89.26\n",
            "\n",
            "Epoch: 39\n",
            "iteration :  50, loss : 0.0518, accuracy : 98.36\n",
            "iteration : 100, loss : 0.0605, accuracy : 97.98\n",
            "iteration : 150, loss : 0.0594, accuracy : 97.96\n",
            "iteration : 200, loss : 0.0614, accuracy : 97.88\n",
            "iteration : 250, loss : 0.0617, accuracy : 97.87\n",
            "iteration : 300, loss : 0.0623, accuracy : 97.81\n",
            "Epoch :  39, training loss : 0.0630, training accuracy : 97.78, val loss : 0.4628, val accuracy : 88.70\n",
            "\n",
            "Epoch: 40\n",
            "iteration :  50, loss : 0.0523, accuracy : 98.22\n",
            "iteration : 100, loss : 0.0560, accuracy : 98.08\n",
            "iteration : 150, loss : 0.0578, accuracy : 98.01\n",
            "iteration : 200, loss : 0.0586, accuracy : 97.95\n",
            "iteration : 250, loss : 0.0580, accuracy : 97.95\n",
            "iteration : 300, loss : 0.0583, accuracy : 97.93\n",
            "Epoch :  40, training loss : 0.0584, training accuracy : 97.91, val loss : 0.4440, val accuracy : 88.93\n",
            "\n",
            "Epoch: 41\n",
            "iteration :  50, loss : 0.0607, accuracy : 97.75\n",
            "iteration : 100, loss : 0.0569, accuracy : 97.94\n",
            "iteration : 150, loss : 0.0540, accuracy : 98.06\n",
            "iteration : 200, loss : 0.0545, accuracy : 98.07\n",
            "iteration : 250, loss : 0.0569, accuracy : 98.03\n",
            "iteration : 300, loss : 0.0568, accuracy : 98.00\n",
            "Epoch :  41, training loss : 0.0574, training accuracy : 97.96, val loss : 0.4716, val accuracy : 88.67\n",
            "\n",
            "Epoch: 42\n",
            "iteration :  50, loss : 0.0578, accuracy : 97.97\n",
            "iteration : 100, loss : 0.0525, accuracy : 98.18\n",
            "iteration : 150, loss : 0.0522, accuracy : 98.20\n",
            "iteration : 200, loss : 0.0552, accuracy : 98.11\n",
            "iteration : 250, loss : 0.0560, accuracy : 98.09\n",
            "iteration : 300, loss : 0.0575, accuracy : 98.01\n",
            "Epoch :  42, training loss : 0.0578, training accuracy : 98.00, val loss : 0.4608, val accuracy : 88.99\n",
            "\n",
            "Epoch: 43\n",
            "iteration :  50, loss : 0.0662, accuracy : 97.58\n",
            "iteration : 100, loss : 0.0631, accuracy : 97.72\n",
            "iteration : 150, loss : 0.0633, accuracy : 97.68\n",
            "iteration : 200, loss : 0.0611, accuracy : 97.79\n",
            "iteration : 250, loss : 0.0609, accuracy : 97.84\n",
            "iteration : 300, loss : 0.0599, accuracy : 97.88\n",
            "Epoch :  43, training loss : 0.0597, training accuracy : 97.89, val loss : 0.4604, val accuracy : 89.20\n",
            "\n",
            "Epoch: 44\n",
            "iteration :  50, loss : 0.0583, accuracy : 98.03\n",
            "iteration : 100, loss : 0.0519, accuracy : 98.23\n",
            "iteration : 150, loss : 0.0481, accuracy : 98.33\n",
            "iteration : 200, loss : 0.0486, accuracy : 98.32\n",
            "iteration : 250, loss : 0.0486, accuracy : 98.35\n",
            "iteration : 300, loss : 0.0498, accuracy : 98.27\n",
            "Epoch :  44, training loss : 0.0502, training accuracy : 98.25, val loss : 0.4245, val accuracy : 89.46\n",
            "\n",
            "Epoch: 45\n",
            "iteration :  50, loss : 0.0405, accuracy : 98.67\n",
            "iteration : 100, loss : 0.0461, accuracy : 98.45\n",
            "iteration : 150, loss : 0.0458, accuracy : 98.42\n",
            "iteration : 200, loss : 0.0486, accuracy : 98.30\n",
            "iteration : 250, loss : 0.0509, accuracy : 98.23\n",
            "iteration : 300, loss : 0.0517, accuracy : 98.19\n",
            "Epoch :  45, training loss : 0.0522, training accuracy : 98.17, val loss : 0.4489, val accuracy : 88.82\n",
            "\n",
            "Epoch: 46\n",
            "iteration :  50, loss : 0.0511, accuracy : 98.19\n",
            "iteration : 100, loss : 0.0466, accuracy : 98.37\n",
            "iteration : 150, loss : 0.0456, accuracy : 98.39\n",
            "iteration : 200, loss : 0.0439, accuracy : 98.42\n",
            "iteration : 250, loss : 0.0447, accuracy : 98.38\n",
            "iteration : 300, loss : 0.0441, accuracy : 98.40\n",
            "Epoch :  46, training loss : 0.0443, training accuracy : 98.39, val loss : 0.4314, val accuracy : 89.55\n",
            "\n",
            "Epoch: 47\n",
            "iteration :  50, loss : 0.0451, accuracy : 98.56\n",
            "iteration : 100, loss : 0.0425, accuracy : 98.62\n",
            "iteration : 150, loss : 0.0433, accuracy : 98.60\n",
            "iteration : 200, loss : 0.0433, accuracy : 98.56\n",
            "iteration : 250, loss : 0.0436, accuracy : 98.52\n",
            "iteration : 300, loss : 0.0445, accuracy : 98.45\n",
            "Epoch :  47, training loss : 0.0453, training accuracy : 98.43, val loss : 0.4641, val accuracy : 89.60\n",
            "\n",
            "Epoch: 48\n",
            "iteration :  50, loss : 0.0501, accuracy : 98.41\n",
            "iteration : 100, loss : 0.0495, accuracy : 98.34\n",
            "iteration : 150, loss : 0.0488, accuracy : 98.35\n",
            "iteration : 200, loss : 0.0487, accuracy : 98.30\n",
            "iteration : 250, loss : 0.0480, accuracy : 98.31\n",
            "iteration : 300, loss : 0.0475, accuracy : 98.32\n",
            "Epoch :  48, training loss : 0.0479, training accuracy : 98.32, val loss : 0.4567, val accuracy : 89.54\n",
            "\n",
            "Epoch: 49\n",
            "iteration :  50, loss : 0.0440, accuracy : 98.50\n",
            "iteration : 100, loss : 0.0412, accuracy : 98.53\n",
            "iteration : 150, loss : 0.0412, accuracy : 98.55\n",
            "iteration : 200, loss : 0.0443, accuracy : 98.45\n",
            "iteration : 250, loss : 0.0448, accuracy : 98.43\n",
            "iteration : 300, loss : 0.0448, accuracy : 98.42\n",
            "Epoch :  49, training loss : 0.0447, training accuracy : 98.42, val loss : 0.4584, val accuracy : 89.47\n",
            "\n",
            "Epoch: 50\n",
            "iteration :  50, loss : 0.0438, accuracy : 98.39\n",
            "iteration : 100, loss : 0.0456, accuracy : 98.30\n",
            "iteration : 150, loss : 0.0437, accuracy : 98.41\n",
            "iteration : 200, loss : 0.0421, accuracy : 98.47\n",
            "iteration : 250, loss : 0.0403, accuracy : 98.54\n",
            "iteration : 300, loss : 0.0397, accuracy : 98.57\n",
            "Epoch :  50, training loss : 0.0393, training accuracy : 98.58, val loss : 0.4447, val accuracy : 89.58\n",
            "\n",
            "Epoch: 51\n",
            "iteration :  50, loss : 0.0453, accuracy : 98.52\n",
            "iteration : 100, loss : 0.0412, accuracy : 98.69\n",
            "iteration : 150, loss : 0.0427, accuracy : 98.57\n",
            "iteration : 200, loss : 0.0428, accuracy : 98.52\n",
            "iteration : 250, loss : 0.0430, accuracy : 98.50\n",
            "iteration : 300, loss : 0.0421, accuracy : 98.55\n",
            "Epoch :  51, training loss : 0.0418, training accuracy : 98.56, val loss : 0.4362, val accuracy : 89.85\n",
            "\n",
            "Epoch: 52\n",
            "iteration :  50, loss : 0.0347, accuracy : 98.70\n",
            "iteration : 100, loss : 0.0353, accuracy : 98.74\n",
            "iteration : 150, loss : 0.0346, accuracy : 98.76\n",
            "iteration : 200, loss : 0.0372, accuracy : 98.61\n",
            "iteration : 250, loss : 0.0385, accuracy : 98.59\n",
            "iteration : 300, loss : 0.0401, accuracy : 98.52\n",
            "Epoch :  52, training loss : 0.0401, training accuracy : 98.52, val loss : 0.4536, val accuracy : 89.57\n",
            "\n",
            "Epoch: 53\n",
            "iteration :  50, loss : 0.0351, accuracy : 98.94\n",
            "iteration : 100, loss : 0.0334, accuracy : 98.93\n",
            "iteration : 150, loss : 0.0353, accuracy : 98.82\n",
            "iteration : 200, loss : 0.0359, accuracy : 98.74\n",
            "iteration : 250, loss : 0.0358, accuracy : 98.75\n",
            "iteration : 300, loss : 0.0369, accuracy : 98.70\n",
            "Epoch :  53, training loss : 0.0368, training accuracy : 98.70, val loss : 0.4646, val accuracy : 89.67\n",
            "\n",
            "Epoch: 54\n",
            "iteration :  50, loss : 0.0401, accuracy : 98.62\n",
            "iteration : 100, loss : 0.0396, accuracy : 98.61\n",
            "iteration : 150, loss : 0.0384, accuracy : 98.67\n",
            "iteration : 200, loss : 0.0397, accuracy : 98.63\n",
            "iteration : 250, loss : 0.0387, accuracy : 98.67\n",
            "iteration : 300, loss : 0.0396, accuracy : 98.64\n",
            "Epoch :  54, training loss : 0.0402, training accuracy : 98.62, val loss : 0.4267, val accuracy : 90.13\n",
            "\n",
            "Epoch: 55\n",
            "iteration :  50, loss : 0.0358, accuracy : 98.75\n",
            "iteration : 100, loss : 0.0363, accuracy : 98.74\n",
            "iteration : 150, loss : 0.0368, accuracy : 98.70\n",
            "iteration : 200, loss : 0.0374, accuracy : 98.68\n",
            "iteration : 250, loss : 0.0384, accuracy : 98.64\n",
            "iteration : 300, loss : 0.0387, accuracy : 98.62\n",
            "Epoch :  55, training loss : 0.0385, training accuracy : 98.62, val loss : 0.4586, val accuracy : 89.78\n",
            "\n",
            "Epoch: 56\n",
            "iteration :  50, loss : 0.0355, accuracy : 98.80\n",
            "iteration : 100, loss : 0.0310, accuracy : 99.02\n",
            "iteration : 150, loss : 0.0319, accuracy : 98.92\n",
            "iteration : 200, loss : 0.0313, accuracy : 98.91\n",
            "iteration : 250, loss : 0.0317, accuracy : 98.87\n",
            "iteration : 300, loss : 0.0314, accuracy : 98.87\n",
            "Epoch :  56, training loss : 0.0316, training accuracy : 98.86, val loss : 0.4145, val accuracy : 90.49\n",
            "\n",
            "Epoch: 57\n",
            "iteration :  50, loss : 0.0215, accuracy : 99.34\n",
            "iteration : 100, loss : 0.0254, accuracy : 99.08\n",
            "iteration : 150, loss : 0.0270, accuracy : 99.00\n",
            "iteration : 200, loss : 0.0258, accuracy : 99.05\n",
            "iteration : 250, loss : 0.0259, accuracy : 99.06\n",
            "iteration : 300, loss : 0.0280, accuracy : 99.00\n",
            "Epoch :  57, training loss : 0.0280, training accuracy : 99.00, val loss : 0.4638, val accuracy : 90.16\n",
            "\n",
            "Epoch: 58\n",
            "iteration :  50, loss : 0.0318, accuracy : 98.84\n",
            "iteration : 100, loss : 0.0305, accuracy : 98.83\n",
            "iteration : 150, loss : 0.0300, accuracy : 98.86\n",
            "iteration : 200, loss : 0.0291, accuracy : 98.90\n",
            "iteration : 250, loss : 0.0298, accuracy : 98.91\n",
            "iteration : 300, loss : 0.0292, accuracy : 98.95\n",
            "Epoch :  58, training loss : 0.0293, training accuracy : 98.95, val loss : 0.4742, val accuracy : 89.63\n",
            "\n",
            "Epoch: 59\n",
            "iteration :  50, loss : 0.0286, accuracy : 99.00\n",
            "iteration : 100, loss : 0.0281, accuracy : 99.04\n",
            "iteration : 150, loss : 0.0271, accuracy : 99.02\n",
            "iteration : 200, loss : 0.0272, accuracy : 99.06\n",
            "iteration : 250, loss : 0.0272, accuracy : 99.05\n",
            "iteration : 300, loss : 0.0277, accuracy : 99.03\n",
            "Epoch :  59, training loss : 0.0276, training accuracy : 99.04, val loss : 0.4618, val accuracy : 90.00\n",
            "\n",
            "Epoch: 60\n",
            "iteration :  50, loss : 0.0298, accuracy : 98.97\n",
            "iteration : 100, loss : 0.0272, accuracy : 99.00\n",
            "iteration : 150, loss : 0.0281, accuracy : 98.97\n",
            "iteration : 200, loss : 0.0286, accuracy : 98.94\n",
            "iteration : 250, loss : 0.0282, accuracy : 98.96\n",
            "iteration : 300, loss : 0.0285, accuracy : 98.97\n",
            "Epoch :  60, training loss : 0.0285, training accuracy : 98.96, val loss : 0.4747, val accuracy : 89.99\n",
            "\n",
            "Epoch: 61\n",
            "iteration :  50, loss : 0.0263, accuracy : 99.11\n",
            "iteration : 100, loss : 0.0243, accuracy : 99.15\n",
            "iteration : 150, loss : 0.0279, accuracy : 99.02\n",
            "iteration : 200, loss : 0.0281, accuracy : 99.05\n",
            "iteration : 250, loss : 0.0264, accuracy : 99.11\n",
            "iteration : 300, loss : 0.0248, accuracy : 99.16\n",
            "Epoch :  61, training loss : 0.0243, training accuracy : 99.17, val loss : 0.4652, val accuracy : 90.22\n",
            "\n",
            "Epoch: 62\n",
            "iteration :  50, loss : 0.0224, accuracy : 99.09\n",
            "iteration : 100, loss : 0.0238, accuracy : 99.09\n",
            "iteration : 150, loss : 0.0250, accuracy : 99.02\n",
            "iteration : 200, loss : 0.0252, accuracy : 99.03\n",
            "iteration : 250, loss : 0.0241, accuracy : 99.08\n",
            "iteration : 300, loss : 0.0239, accuracy : 99.09\n",
            "Epoch :  62, training loss : 0.0239, training accuracy : 99.10, val loss : 0.4476, val accuracy : 90.76\n",
            "\n",
            "Epoch: 63\n",
            "iteration :  50, loss : 0.0312, accuracy : 98.78\n",
            "iteration : 100, loss : 0.0276, accuracy : 98.99\n",
            "iteration : 150, loss : 0.0265, accuracy : 99.05\n",
            "iteration : 200, loss : 0.0286, accuracy : 98.97\n",
            "iteration : 250, loss : 0.0293, accuracy : 98.95\n",
            "iteration : 300, loss : 0.0293, accuracy : 98.96\n",
            "Epoch :  63, training loss : 0.0294, training accuracy : 98.97, val loss : 0.4909, val accuracy : 89.86\n",
            "\n",
            "Epoch: 64\n",
            "iteration :  50, loss : 0.0294, accuracy : 98.92\n",
            "iteration : 100, loss : 0.0280, accuracy : 98.96\n",
            "iteration : 150, loss : 0.0287, accuracy : 98.93\n",
            "iteration : 200, loss : 0.0293, accuracy : 98.94\n",
            "iteration : 250, loss : 0.0283, accuracy : 98.99\n",
            "iteration : 300, loss : 0.0277, accuracy : 99.01\n",
            "Epoch :  64, training loss : 0.0274, training accuracy : 99.03, val loss : 0.4451, val accuracy : 90.50\n",
            "\n",
            "Epoch: 65\n",
            "iteration :  50, loss : 0.0246, accuracy : 99.05\n",
            "iteration : 100, loss : 0.0222, accuracy : 99.21\n",
            "iteration : 150, loss : 0.0224, accuracy : 99.22\n",
            "iteration : 200, loss : 0.0221, accuracy : 99.23\n",
            "iteration : 250, loss : 0.0221, accuracy : 99.21\n",
            "iteration : 300, loss : 0.0222, accuracy : 99.18\n",
            "Epoch :  65, training loss : 0.0223, training accuracy : 99.18, val loss : 0.4902, val accuracy : 89.89\n",
            "\n",
            "Epoch: 66\n",
            "iteration :  50, loss : 0.0223, accuracy : 99.16\n",
            "iteration : 100, loss : 0.0238, accuracy : 99.13\n",
            "iteration : 150, loss : 0.0230, accuracy : 99.20\n",
            "iteration : 200, loss : 0.0235, accuracy : 99.19\n",
            "iteration : 250, loss : 0.0239, accuracy : 99.17\n",
            "iteration : 300, loss : 0.0237, accuracy : 99.17\n",
            "Epoch :  66, training loss : 0.0238, training accuracy : 99.17, val loss : 0.4532, val accuracy : 90.68\n",
            "\n",
            "Epoch: 67\n",
            "iteration :  50, loss : 0.0190, accuracy : 99.31\n",
            "iteration : 100, loss : 0.0206, accuracy : 99.30\n",
            "iteration : 150, loss : 0.0220, accuracy : 99.29\n",
            "iteration : 200, loss : 0.0218, accuracy : 99.28\n",
            "iteration : 250, loss : 0.0222, accuracy : 99.24\n",
            "iteration : 300, loss : 0.0233, accuracy : 99.21\n",
            "Epoch :  67, training loss : 0.0241, training accuracy : 99.18, val loss : 0.4710, val accuracy : 90.17\n",
            "\n",
            "Epoch: 68\n",
            "iteration :  50, loss : 0.0201, accuracy : 99.28\n",
            "iteration : 100, loss : 0.0209, accuracy : 99.23\n",
            "iteration : 150, loss : 0.0201, accuracy : 99.31\n",
            "iteration : 200, loss : 0.0199, accuracy : 99.32\n",
            "iteration : 250, loss : 0.0191, accuracy : 99.35\n",
            "iteration : 300, loss : 0.0187, accuracy : 99.37\n",
            "Epoch :  68, training loss : 0.0185, training accuracy : 99.39, val loss : 0.4475, val accuracy : 90.72\n",
            "\n",
            "Epoch: 69\n",
            "iteration :  50, loss : 0.0147, accuracy : 99.55\n",
            "iteration : 100, loss : 0.0137, accuracy : 99.54\n",
            "iteration : 150, loss : 0.0153, accuracy : 99.49\n",
            "iteration : 200, loss : 0.0170, accuracy : 99.43\n",
            "iteration : 250, loss : 0.0186, accuracy : 99.36\n",
            "iteration : 300, loss : 0.0196, accuracy : 99.31\n",
            "Epoch :  69, training loss : 0.0195, training accuracy : 99.32, val loss : 0.4330, val accuracy : 91.01\n",
            "\n",
            "Epoch: 70\n",
            "iteration :  50, loss : 0.0157, accuracy : 99.55\n",
            "iteration : 100, loss : 0.0176, accuracy : 99.38\n",
            "iteration : 150, loss : 0.0175, accuracy : 99.39\n",
            "iteration : 200, loss : 0.0185, accuracy : 99.34\n",
            "iteration : 250, loss : 0.0211, accuracy : 99.26\n",
            "iteration : 300, loss : 0.0222, accuracy : 99.24\n",
            "Epoch :  70, training loss : 0.0223, training accuracy : 99.24, val loss : 0.4581, val accuracy : 90.70\n",
            "\n",
            "Epoch: 71\n",
            "iteration :  50, loss : 0.0177, accuracy : 99.36\n",
            "iteration : 100, loss : 0.0178, accuracy : 99.38\n",
            "iteration : 150, loss : 0.0189, accuracy : 99.36\n",
            "iteration : 200, loss : 0.0179, accuracy : 99.41\n",
            "iteration : 250, loss : 0.0176, accuracy : 99.41\n",
            "iteration : 300, loss : 0.0181, accuracy : 99.39\n",
            "Epoch :  71, training loss : 0.0183, training accuracy : 99.39, val loss : 0.4786, val accuracy : 90.70\n",
            "\n",
            "Epoch: 72\n",
            "iteration :  50, loss : 0.0201, accuracy : 99.33\n",
            "iteration : 100, loss : 0.0196, accuracy : 99.34\n",
            "iteration : 150, loss : 0.0181, accuracy : 99.36\n",
            "iteration : 200, loss : 0.0182, accuracy : 99.37\n",
            "iteration : 250, loss : 0.0199, accuracy : 99.32\n",
            "iteration : 300, loss : 0.0202, accuracy : 99.31\n",
            "Epoch :  72, training loss : 0.0206, training accuracy : 99.31, val loss : 0.5143, val accuracy : 90.06\n",
            "\n",
            "Epoch: 73\n",
            "iteration :  50, loss : 0.0259, accuracy : 99.08\n",
            "iteration : 100, loss : 0.0265, accuracy : 99.07\n",
            "iteration : 150, loss : 0.0263, accuracy : 99.07\n",
            "iteration : 200, loss : 0.0268, accuracy : 99.10\n",
            "iteration : 250, loss : 0.0260, accuracy : 99.12\n",
            "iteration : 300, loss : 0.0245, accuracy : 99.18\n",
            "Epoch :  73, training loss : 0.0244, training accuracy : 99.19, val loss : 0.4460, val accuracy : 90.70\n",
            "\n",
            "Epoch: 74\n",
            "iteration :  50, loss : 0.0164, accuracy : 99.38\n",
            "iteration : 100, loss : 0.0184, accuracy : 99.35\n",
            "iteration : 150, loss : 0.0180, accuracy : 99.33\n",
            "iteration : 200, loss : 0.0185, accuracy : 99.32\n",
            "iteration : 250, loss : 0.0192, accuracy : 99.31\n",
            "iteration : 300, loss : 0.0195, accuracy : 99.30\n",
            "Epoch :  74, training loss : 0.0190, training accuracy : 99.32, val loss : 0.4647, val accuracy : 90.80\n",
            "\n",
            "Epoch: 75\n",
            "iteration :  50, loss : 0.0176, accuracy : 99.38\n",
            "iteration : 100, loss : 0.0170, accuracy : 99.38\n",
            "iteration : 150, loss : 0.0167, accuracy : 99.41\n",
            "iteration : 200, loss : 0.0162, accuracy : 99.43\n",
            "iteration : 250, loss : 0.0155, accuracy : 99.46\n",
            "iteration : 300, loss : 0.0162, accuracy : 99.43\n",
            "Epoch :  75, training loss : 0.0161, training accuracy : 99.43, val loss : 0.4582, val accuracy : 90.60\n",
            "\n",
            "Epoch: 76\n",
            "iteration :  50, loss : 0.0146, accuracy : 99.39\n",
            "iteration : 100, loss : 0.0142, accuracy : 99.47\n",
            "iteration : 150, loss : 0.0151, accuracy : 99.46\n",
            "iteration : 200, loss : 0.0147, accuracy : 99.49\n",
            "iteration : 250, loss : 0.0146, accuracy : 99.51\n",
            "iteration : 300, loss : 0.0144, accuracy : 99.51\n",
            "Epoch :  76, training loss : 0.0143, training accuracy : 99.51, val loss : 0.4652, val accuracy : 90.72\n",
            "\n",
            "Epoch: 77\n",
            "iteration :  50, loss : 0.0143, accuracy : 99.47\n",
            "iteration : 100, loss : 0.0159, accuracy : 99.45\n",
            "iteration : 150, loss : 0.0149, accuracy : 99.47\n",
            "iteration : 200, loss : 0.0145, accuracy : 99.48\n",
            "iteration : 250, loss : 0.0144, accuracy : 99.49\n",
            "iteration : 300, loss : 0.0148, accuracy : 99.46\n",
            "Epoch :  77, training loss : 0.0148, training accuracy : 99.46, val loss : 0.4586, val accuracy : 90.85\n",
            "\n",
            "Epoch: 78\n",
            "iteration :  50, loss : 0.0156, accuracy : 99.42\n",
            "iteration : 100, loss : 0.0151, accuracy : 99.49\n",
            "iteration : 150, loss : 0.0139, accuracy : 99.54\n",
            "iteration : 200, loss : 0.0143, accuracy : 99.52\n",
            "iteration : 250, loss : 0.0145, accuracy : 99.50\n",
            "iteration : 300, loss : 0.0147, accuracy : 99.49\n",
            "Epoch :  78, training loss : 0.0149, training accuracy : 99.49, val loss : 0.4977, val accuracy : 90.16\n",
            "\n",
            "Epoch: 79\n",
            "iteration :  50, loss : 0.0243, accuracy : 99.09\n",
            "iteration : 100, loss : 0.0207, accuracy : 99.23\n",
            "iteration : 150, loss : 0.0191, accuracy : 99.31\n",
            "iteration : 200, loss : 0.0182, accuracy : 99.36\n",
            "iteration : 250, loss : 0.0171, accuracy : 99.41\n",
            "iteration : 300, loss : 0.0173, accuracy : 99.40\n",
            "Epoch :  79, training loss : 0.0173, training accuracy : 99.40, val loss : 0.4465, val accuracy : 90.81\n",
            "\n",
            "Epoch: 80\n",
            "iteration :  50, loss : 0.0128, accuracy : 99.58\n",
            "iteration : 100, loss : 0.0112, accuracy : 99.62\n",
            "iteration : 150, loss : 0.0104, accuracy : 99.67\n",
            "iteration : 200, loss : 0.0115, accuracy : 99.62\n",
            "iteration : 250, loss : 0.0133, accuracy : 99.55\n",
            "iteration : 300, loss : 0.0131, accuracy : 99.56\n",
            "Epoch :  80, training loss : 0.0131, training accuracy : 99.56, val loss : 0.4937, val accuracy : 90.45\n",
            "\n",
            "Epoch: 81\n",
            "iteration :  50, loss : 0.0199, accuracy : 99.42\n",
            "iteration : 100, loss : 0.0199, accuracy : 99.34\n",
            "iteration : 150, loss : 0.0200, accuracy : 99.31\n",
            "iteration : 200, loss : 0.0205, accuracy : 99.30\n",
            "iteration : 250, loss : 0.0200, accuracy : 99.30\n",
            "iteration : 300, loss : 0.0197, accuracy : 99.30\n",
            "Epoch :  81, training loss : 0.0196, training accuracy : 99.31, val loss : 0.4816, val accuracy : 90.30\n",
            "\n",
            "Epoch: 82\n",
            "iteration :  50, loss : 0.0120, accuracy : 99.58\n",
            "iteration : 100, loss : 0.0122, accuracy : 99.57\n",
            "iteration : 150, loss : 0.0123, accuracy : 99.58\n",
            "iteration : 200, loss : 0.0127, accuracy : 99.56\n",
            "iteration : 250, loss : 0.0139, accuracy : 99.53\n",
            "iteration : 300, loss : 0.0140, accuracy : 99.51\n",
            "Epoch :  82, training loss : 0.0141, training accuracy : 99.50, val loss : 0.4951, val accuracy : 90.36\n",
            "\n",
            "Epoch: 83\n",
            "iteration :  50, loss : 0.0172, accuracy : 99.41\n",
            "iteration : 100, loss : 0.0167, accuracy : 99.40\n",
            "iteration : 150, loss : 0.0179, accuracy : 99.40\n",
            "iteration : 200, loss : 0.0170, accuracy : 99.43\n",
            "iteration : 250, loss : 0.0168, accuracy : 99.42\n",
            "iteration : 300, loss : 0.0170, accuracy : 99.43\n",
            "Epoch :  83, training loss : 0.0174, training accuracy : 99.42, val loss : 0.4949, val accuracy : 90.63\n",
            "\n",
            "Epoch: 84\n",
            "iteration :  50, loss : 0.0224, accuracy : 99.17\n",
            "iteration : 100, loss : 0.0195, accuracy : 99.27\n",
            "iteration : 150, loss : 0.0179, accuracy : 99.31\n",
            "iteration : 200, loss : 0.0184, accuracy : 99.30\n",
            "iteration : 250, loss : 0.0180, accuracy : 99.33\n",
            "iteration : 300, loss : 0.0177, accuracy : 99.36\n",
            "Epoch :  84, training loss : 0.0174, training accuracy : 99.38, val loss : 0.4591, val accuracy : 90.98\n",
            "\n",
            "Epoch: 85\n",
            "iteration :  50, loss : 0.0186, accuracy : 99.30\n",
            "iteration : 100, loss : 0.0142, accuracy : 99.47\n",
            "iteration : 150, loss : 0.0157, accuracy : 99.40\n",
            "iteration : 200, loss : 0.0157, accuracy : 99.41\n",
            "iteration : 250, loss : 0.0150, accuracy : 99.44\n",
            "iteration : 300, loss : 0.0151, accuracy : 99.45\n",
            "Epoch :  85, training loss : 0.0150, training accuracy : 99.46, val loss : 0.4891, val accuracy : 90.76\n",
            "\n",
            "Epoch: 86\n",
            "iteration :  50, loss : 0.0146, accuracy : 99.52\n",
            "iteration : 100, loss : 0.0135, accuracy : 99.51\n",
            "iteration : 150, loss : 0.0139, accuracy : 99.52\n",
            "iteration : 200, loss : 0.0142, accuracy : 99.49\n",
            "iteration : 250, loss : 0.0139, accuracy : 99.50\n",
            "iteration : 300, loss : 0.0145, accuracy : 99.48\n",
            "Epoch :  86, training loss : 0.0145, training accuracy : 99.49, val loss : 0.4764, val accuracy : 90.70\n",
            "\n",
            "Epoch: 87\n",
            "iteration :  50, loss : 0.0124, accuracy : 99.55\n",
            "iteration : 100, loss : 0.0126, accuracy : 99.54\n",
            "iteration : 150, loss : 0.0142, accuracy : 99.51\n",
            "iteration : 200, loss : 0.0136, accuracy : 99.51\n",
            "iteration : 250, loss : 0.0131, accuracy : 99.55\n",
            "iteration : 300, loss : 0.0133, accuracy : 99.56\n",
            "Epoch :  87, training loss : 0.0135, training accuracy : 99.56, val loss : 0.4879, val accuracy : 90.67\n",
            "\n",
            "Epoch: 88\n",
            "iteration :  50, loss : 0.0143, accuracy : 99.48\n",
            "iteration : 100, loss : 0.0139, accuracy : 99.48\n",
            "iteration : 150, loss : 0.0148, accuracy : 99.46\n",
            "iteration : 200, loss : 0.0147, accuracy : 99.48\n",
            "iteration : 250, loss : 0.0143, accuracy : 99.49\n",
            "iteration : 300, loss : 0.0141, accuracy : 99.52\n",
            "Epoch :  88, training loss : 0.0143, training accuracy : 99.51, val loss : 0.4796, val accuracy : 90.66\n",
            "\n",
            "Epoch: 89\n",
            "iteration :  50, loss : 0.0132, accuracy : 99.45\n",
            "iteration : 100, loss : 0.0122, accuracy : 99.55\n",
            "iteration : 150, loss : 0.0116, accuracy : 99.59\n",
            "iteration : 200, loss : 0.0115, accuracy : 99.59\n",
            "iteration : 250, loss : 0.0114, accuracy : 99.60\n",
            "iteration : 300, loss : 0.0118, accuracy : 99.59\n",
            "Epoch :  89, training loss : 0.0116, training accuracy : 99.59, val loss : 0.4848, val accuracy : 91.29\n",
            "\n",
            "Epoch: 90\n",
            "iteration :  50, loss : 0.0102, accuracy : 99.69\n",
            "iteration : 100, loss : 0.0087, accuracy : 99.70\n",
            "iteration : 150, loss : 0.0094, accuracy : 99.68\n",
            "iteration : 200, loss : 0.0096, accuracy : 99.67\n",
            "iteration : 250, loss : 0.0096, accuracy : 99.68\n",
            "iteration : 300, loss : 0.0099, accuracy : 99.67\n",
            "Epoch :  90, training loss : 0.0099, training accuracy : 99.67, val loss : 0.4777, val accuracy : 90.78\n",
            "\n",
            "Epoch: 91\n",
            "iteration :  50, loss : 0.0130, accuracy : 99.52\n",
            "iteration : 100, loss : 0.0126, accuracy : 99.52\n",
            "iteration : 150, loss : 0.0117, accuracy : 99.58\n",
            "iteration : 200, loss : 0.0109, accuracy : 99.62\n",
            "iteration : 250, loss : 0.0110, accuracy : 99.61\n",
            "iteration : 300, loss : 0.0112, accuracy : 99.60\n",
            "Epoch :  91, training loss : 0.0111, training accuracy : 99.61, val loss : 0.4741, val accuracy : 90.84\n",
            "\n",
            "Epoch: 92\n",
            "iteration :  50, loss : 0.0112, accuracy : 99.66\n",
            "iteration : 100, loss : 0.0103, accuracy : 99.66\n",
            "iteration : 150, loss : 0.0100, accuracy : 99.67\n",
            "iteration : 200, loss : 0.0097, accuracy : 99.70\n",
            "iteration : 250, loss : 0.0100, accuracy : 99.68\n",
            "iteration : 300, loss : 0.0101, accuracy : 99.68\n",
            "Epoch :  92, training loss : 0.0101, training accuracy : 99.67, val loss : 0.4760, val accuracy : 91.25\n",
            "\n",
            "Epoch: 93\n",
            "iteration :  50, loss : 0.0079, accuracy : 99.73\n",
            "iteration : 100, loss : 0.0099, accuracy : 99.66\n",
            "iteration : 150, loss : 0.0095, accuracy : 99.69\n",
            "iteration : 200, loss : 0.0098, accuracy : 99.66\n",
            "iteration : 250, loss : 0.0102, accuracy : 99.65\n",
            "iteration : 300, loss : 0.0104, accuracy : 99.64\n",
            "Epoch :  93, training loss : 0.0104, training accuracy : 99.64, val loss : 0.4731, val accuracy : 91.01\n",
            "\n",
            "Epoch: 94\n",
            "iteration :  50, loss : 0.0120, accuracy : 99.55\n",
            "iteration : 100, loss : 0.0146, accuracy : 99.45\n",
            "iteration : 150, loss : 0.0150, accuracy : 99.45\n",
            "iteration : 200, loss : 0.0144, accuracy : 99.49\n",
            "iteration : 250, loss : 0.0136, accuracy : 99.51\n",
            "iteration : 300, loss : 0.0133, accuracy : 99.53\n",
            "Epoch :  94, training loss : 0.0131, training accuracy : 99.53, val loss : 0.4749, val accuracy : 91.24\n",
            "\n",
            "Epoch: 95\n",
            "iteration :  50, loss : 0.0143, accuracy : 99.41\n",
            "iteration : 100, loss : 0.0118, accuracy : 99.50\n",
            "iteration : 150, loss : 0.0114, accuracy : 99.55\n",
            "iteration : 200, loss : 0.0117, accuracy : 99.55\n",
            "iteration : 250, loss : 0.0105, accuracy : 99.61\n",
            "iteration : 300, loss : 0.0100, accuracy : 99.64\n",
            "Epoch :  95, training loss : 0.0103, training accuracy : 99.64, val loss : 0.4578, val accuracy : 91.05\n",
            "\n",
            "Epoch: 96\n",
            "iteration :  50, loss : 0.0166, accuracy : 99.48\n",
            "iteration : 100, loss : 0.0150, accuracy : 99.52\n",
            "iteration : 150, loss : 0.0135, accuracy : 99.55\n",
            "iteration : 200, loss : 0.0134, accuracy : 99.56\n",
            "iteration : 250, loss : 0.0126, accuracy : 99.58\n",
            "iteration : 300, loss : 0.0123, accuracy : 99.58\n",
            "Epoch :  96, training loss : 0.0121, training accuracy : 99.59, val loss : 0.4633, val accuracy : 91.25\n",
            "\n",
            "Epoch: 97\n",
            "iteration :  50, loss : 0.0100, accuracy : 99.69\n",
            "iteration : 100, loss : 0.0092, accuracy : 99.71\n",
            "iteration : 150, loss : 0.0084, accuracy : 99.73\n",
            "iteration : 200, loss : 0.0086, accuracy : 99.73\n",
            "iteration : 250, loss : 0.0090, accuracy : 99.72\n",
            "iteration : 300, loss : 0.0093, accuracy : 99.72\n",
            "Epoch :  97, training loss : 0.0094, training accuracy : 99.71, val loss : 0.5031, val accuracy : 91.13\n",
            "\n",
            "Epoch: 98\n",
            "iteration :  50, loss : 0.0099, accuracy : 99.72\n",
            "iteration : 100, loss : 0.0114, accuracy : 99.62\n",
            "iteration : 150, loss : 0.0127, accuracy : 99.58\n",
            "iteration : 200, loss : 0.0130, accuracy : 99.58\n",
            "iteration : 250, loss : 0.0136, accuracy : 99.54\n",
            "iteration : 300, loss : 0.0142, accuracy : 99.52\n",
            "Epoch :  98, training loss : 0.0143, training accuracy : 99.52, val loss : 0.4798, val accuracy : 91.00\n",
            "\n",
            "Epoch: 99\n",
            "iteration :  50, loss : 0.0150, accuracy : 99.48\n",
            "iteration : 100, loss : 0.0128, accuracy : 99.53\n",
            "iteration : 150, loss : 0.0115, accuracy : 99.58\n",
            "iteration : 200, loss : 0.0111, accuracy : 99.59\n",
            "iteration : 250, loss : 0.0111, accuracy : 99.60\n",
            "iteration : 300, loss : 0.0115, accuracy : 99.59\n",
            "Epoch :  99, training loss : 0.0113, training accuracy : 99.59, val loss : 0.5102, val accuracy : 90.68\n",
            "\n",
            "Epoch: 100\n",
            "iteration :  50, loss : 0.0167, accuracy : 99.39\n",
            "iteration : 100, loss : 0.0152, accuracy : 99.52\n",
            "iteration : 150, loss : 0.0148, accuracy : 99.49\n",
            "iteration : 200, loss : 0.0143, accuracy : 99.51\n",
            "iteration : 250, loss : 0.0137, accuracy : 99.53\n",
            "iteration : 300, loss : 0.0132, accuracy : 99.55\n",
            "Epoch : 100, training loss : 0.0132, training accuracy : 99.55, val loss : 0.4820, val accuracy : 90.91\n",
            "\n",
            "Epoch: 101\n",
            "iteration :  50, loss : 0.0087, accuracy : 99.67\n",
            "iteration : 100, loss : 0.0081, accuracy : 99.73\n",
            "iteration : 150, loss : 0.0080, accuracy : 99.73\n",
            "iteration : 200, loss : 0.0079, accuracy : 99.73\n",
            "iteration : 250, loss : 0.0081, accuracy : 99.72\n",
            "iteration : 300, loss : 0.0082, accuracy : 99.71\n",
            "Epoch : 101, training loss : 0.0084, training accuracy : 99.71, val loss : 0.4890, val accuracy : 91.22\n",
            "\n",
            "Epoch: 102\n",
            "iteration :  50, loss : 0.0072, accuracy : 99.73\n",
            "iteration : 100, loss : 0.0083, accuracy : 99.71\n",
            "iteration : 150, loss : 0.0086, accuracy : 99.72\n",
            "iteration : 200, loss : 0.0086, accuracy : 99.73\n",
            "iteration : 250, loss : 0.0086, accuracy : 99.72\n",
            "iteration : 300, loss : 0.0090, accuracy : 99.72\n",
            "Epoch : 102, training loss : 0.0091, training accuracy : 99.72, val loss : 0.4829, val accuracy : 91.18\n",
            "\n",
            "Epoch: 103\n",
            "iteration :  50, loss : 0.0089, accuracy : 99.67\n",
            "iteration : 100, loss : 0.0086, accuracy : 99.69\n",
            "iteration : 150, loss : 0.0082, accuracy : 99.71\n",
            "iteration : 200, loss : 0.0085, accuracy : 99.70\n",
            "iteration : 250, loss : 0.0086, accuracy : 99.70\n",
            "iteration : 300, loss : 0.0086, accuracy : 99.70\n",
            "Epoch : 103, training loss : 0.0086, training accuracy : 99.70, val loss : 0.5242, val accuracy : 90.69\n",
            "\n",
            "Epoch: 104\n",
            "iteration :  50, loss : 0.0114, accuracy : 99.59\n",
            "iteration : 100, loss : 0.0100, accuracy : 99.64\n",
            "iteration : 150, loss : 0.0099, accuracy : 99.64\n",
            "iteration : 200, loss : 0.0091, accuracy : 99.68\n",
            "iteration : 250, loss : 0.0089, accuracy : 99.69\n",
            "iteration : 300, loss : 0.0093, accuracy : 99.69\n",
            "Epoch : 104, training loss : 0.0093, training accuracy : 99.69, val loss : 0.4829, val accuracy : 91.04\n",
            "\n",
            "Epoch: 105\n",
            "iteration :  50, loss : 0.0109, accuracy : 99.56\n",
            "iteration : 100, loss : 0.0138, accuracy : 99.47\n",
            "iteration : 150, loss : 0.0129, accuracy : 99.53\n",
            "iteration : 200, loss : 0.0119, accuracy : 99.58\n",
            "iteration : 250, loss : 0.0114, accuracy : 99.59\n",
            "iteration : 300, loss : 0.0106, accuracy : 99.61\n",
            "Epoch : 105, training loss : 0.0104, training accuracy : 99.62, val loss : 0.4625, val accuracy : 91.53\n",
            "\n",
            "Epoch: 106\n",
            "iteration :  50, loss : 0.0071, accuracy : 99.77\n",
            "iteration : 100, loss : 0.0064, accuracy : 99.80\n",
            "iteration : 150, loss : 0.0065, accuracy : 99.80\n",
            "iteration : 200, loss : 0.0065, accuracy : 99.80\n",
            "iteration : 250, loss : 0.0064, accuracy : 99.79\n",
            "iteration : 300, loss : 0.0066, accuracy : 99.78\n",
            "Epoch : 106, training loss : 0.0066, training accuracy : 99.78, val loss : 0.4874, val accuracy : 91.10\n",
            "\n",
            "Epoch: 107\n",
            "iteration :  50, loss : 0.0074, accuracy : 99.83\n",
            "iteration : 100, loss : 0.0066, accuracy : 99.83\n",
            "iteration : 150, loss : 0.0069, accuracy : 99.79\n",
            "iteration : 200, loss : 0.0069, accuracy : 99.79\n",
            "iteration : 250, loss : 0.0071, accuracy : 99.78\n",
            "iteration : 300, loss : 0.0077, accuracy : 99.74\n",
            "Epoch : 107, training loss : 0.0077, training accuracy : 99.75, val loss : 0.5035, val accuracy : 90.90\n",
            "\n",
            "Epoch: 108\n",
            "iteration :  50, loss : 0.0110, accuracy : 99.64\n",
            "iteration : 100, loss : 0.0093, accuracy : 99.70\n",
            "iteration : 150, loss : 0.0090, accuracy : 99.70\n",
            "iteration : 200, loss : 0.0083, accuracy : 99.72\n",
            "iteration : 250, loss : 0.0076, accuracy : 99.75\n",
            "iteration : 300, loss : 0.0075, accuracy : 99.75\n",
            "Epoch : 108, training loss : 0.0074, training accuracy : 99.75, val loss : 0.4862, val accuracy : 91.16\n",
            "\n",
            "Epoch: 109\n",
            "iteration :  50, loss : 0.0068, accuracy : 99.73\n",
            "iteration : 100, loss : 0.0091, accuracy : 99.63\n",
            "iteration : 150, loss : 0.0101, accuracy : 99.60\n",
            "iteration : 200, loss : 0.0103, accuracy : 99.61\n",
            "iteration : 250, loss : 0.0107, accuracy : 99.59\n",
            "iteration : 300, loss : 0.0109, accuracy : 99.59\n",
            "Epoch : 109, training loss : 0.0107, training accuracy : 99.61, val loss : 0.4972, val accuracy : 90.82\n",
            "\n",
            "Epoch: 110\n",
            "iteration :  50, loss : 0.0066, accuracy : 99.78\n",
            "iteration : 100, loss : 0.0082, accuracy : 99.76\n",
            "iteration : 150, loss : 0.0080, accuracy : 99.77\n",
            "iteration : 200, loss : 0.0085, accuracy : 99.73\n",
            "iteration : 250, loss : 0.0079, accuracy : 99.75\n",
            "iteration : 300, loss : 0.0080, accuracy : 99.73\n",
            "Epoch : 110, training loss : 0.0082, training accuracy : 99.72, val loss : 0.5033, val accuracy : 90.74\n",
            "\n",
            "Epoch: 111\n",
            "iteration :  50, loss : 0.0096, accuracy : 99.66\n",
            "iteration : 100, loss : 0.0084, accuracy : 99.71\n",
            "iteration : 150, loss : 0.0078, accuracy : 99.75\n",
            "iteration : 200, loss : 0.0075, accuracy : 99.75\n",
            "iteration : 250, loss : 0.0073, accuracy : 99.77\n",
            "iteration : 300, loss : 0.0073, accuracy : 99.77\n",
            "Epoch : 111, training loss : 0.0072, training accuracy : 99.77, val loss : 0.4886, val accuracy : 91.38\n",
            "\n",
            "Epoch: 112\n",
            "iteration :  50, loss : 0.0053, accuracy : 99.80\n",
            "iteration : 100, loss : 0.0050, accuracy : 99.84\n",
            "iteration : 150, loss : 0.0055, accuracy : 99.82\n",
            "iteration : 200, loss : 0.0066, accuracy : 99.80\n",
            "iteration : 250, loss : 0.0066, accuracy : 99.79\n",
            "iteration : 300, loss : 0.0066, accuracy : 99.78\n",
            "Epoch : 112, training loss : 0.0066, training accuracy : 99.78, val loss : 0.4892, val accuracy : 91.34\n",
            "\n",
            "Epoch: 113\n",
            "iteration :  50, loss : 0.0043, accuracy : 99.89\n",
            "iteration : 100, loss : 0.0070, accuracy : 99.74\n",
            "iteration : 150, loss : 0.0085, accuracy : 99.69\n",
            "iteration : 200, loss : 0.0081, accuracy : 99.71\n",
            "iteration : 250, loss : 0.0079, accuracy : 99.72\n",
            "iteration : 300, loss : 0.0077, accuracy : 99.73\n",
            "Epoch : 113, training loss : 0.0079, training accuracy : 99.72, val loss : 0.5537, val accuracy : 90.56\n",
            "\n",
            "Epoch: 114\n",
            "iteration :  50, loss : 0.0073, accuracy : 99.80\n",
            "iteration : 100, loss : 0.0072, accuracy : 99.80\n",
            "iteration : 150, loss : 0.0064, accuracy : 99.82\n",
            "iteration : 200, loss : 0.0064, accuracy : 99.81\n",
            "iteration : 250, loss : 0.0066, accuracy : 99.81\n",
            "iteration : 300, loss : 0.0066, accuracy : 99.80\n",
            "Epoch : 114, training loss : 0.0067, training accuracy : 99.80, val loss : 0.5046, val accuracy : 90.86\n",
            "\n",
            "Epoch: 115\n",
            "iteration :  50, loss : 0.0076, accuracy : 99.78\n",
            "iteration : 100, loss : 0.0085, accuracy : 99.73\n",
            "iteration : 150, loss : 0.0084, accuracy : 99.72\n",
            "iteration : 200, loss : 0.0078, accuracy : 99.74\n",
            "iteration : 250, loss : 0.0077, accuracy : 99.75\n",
            "iteration : 300, loss : 0.0077, accuracy : 99.75\n",
            "Epoch : 115, training loss : 0.0077, training accuracy : 99.75, val loss : 0.5193, val accuracy : 91.01\n",
            "\n",
            "Epoch: 116\n",
            "iteration :  50, loss : 0.0091, accuracy : 99.67\n",
            "iteration : 100, loss : 0.0071, accuracy : 99.73\n",
            "iteration : 150, loss : 0.0069, accuracy : 99.74\n",
            "iteration : 200, loss : 0.0067, accuracy : 99.77\n",
            "iteration : 250, loss : 0.0065, accuracy : 99.78\n",
            "iteration : 300, loss : 0.0062, accuracy : 99.79\n",
            "Epoch : 116, training loss : 0.0062, training accuracy : 99.79, val loss : 0.4956, val accuracy : 91.38\n",
            "\n",
            "Epoch: 117\n",
            "iteration :  50, loss : 0.0051, accuracy : 99.81\n",
            "iteration : 100, loss : 0.0054, accuracy : 99.84\n",
            "iteration : 150, loss : 0.0055, accuracy : 99.83\n",
            "iteration : 200, loss : 0.0058, accuracy : 99.83\n",
            "iteration : 250, loss : 0.0060, accuracy : 99.83\n",
            "iteration : 300, loss : 0.0061, accuracy : 99.82\n",
            "Epoch : 117, training loss : 0.0061, training accuracy : 99.81, val loss : 0.4807, val accuracy : 91.47\n",
            "\n",
            "Epoch: 118\n",
            "iteration :  50, loss : 0.0045, accuracy : 99.89\n",
            "iteration : 100, loss : 0.0052, accuracy : 99.83\n",
            "iteration : 150, loss : 0.0053, accuracy : 99.81\n",
            "iteration : 200, loss : 0.0054, accuracy : 99.81\n",
            "iteration : 250, loss : 0.0055, accuracy : 99.81\n",
            "iteration : 300, loss : 0.0057, accuracy : 99.80\n",
            "Epoch : 118, training loss : 0.0056, training accuracy : 99.81, val loss : 0.4885, val accuracy : 91.16\n",
            "\n",
            "Epoch: 119\n",
            "iteration :  50, loss : 0.0060, accuracy : 99.81\n",
            "iteration : 100, loss : 0.0058, accuracy : 99.78\n",
            "iteration : 150, loss : 0.0060, accuracy : 99.79\n",
            "iteration : 200, loss : 0.0060, accuracy : 99.79\n",
            "iteration : 250, loss : 0.0070, accuracy : 99.75\n",
            "iteration : 300, loss : 0.0070, accuracy : 99.76\n",
            "Epoch : 119, training loss : 0.0070, training accuracy : 99.75, val loss : 0.4906, val accuracy : 91.19\n",
            "\n",
            "Epoch: 120\n",
            "iteration :  50, loss : 0.0060, accuracy : 99.86\n",
            "iteration : 100, loss : 0.0051, accuracy : 99.87\n",
            "iteration : 150, loss : 0.0053, accuracy : 99.85\n",
            "iteration : 200, loss : 0.0052, accuracy : 99.85\n",
            "iteration : 250, loss : 0.0054, accuracy : 99.84\n",
            "iteration : 300, loss : 0.0055, accuracy : 99.83\n",
            "Epoch : 120, training loss : 0.0056, training accuracy : 99.83, val loss : 0.4774, val accuracy : 91.61\n",
            "\n",
            "Epoch: 121\n",
            "iteration :  50, loss : 0.0074, accuracy : 99.77\n",
            "iteration : 100, loss : 0.0062, accuracy : 99.78\n",
            "iteration : 150, loss : 0.0057, accuracy : 99.80\n",
            "iteration : 200, loss : 0.0058, accuracy : 99.79\n",
            "iteration : 250, loss : 0.0063, accuracy : 99.77\n",
            "iteration : 300, loss : 0.0068, accuracy : 99.76\n",
            "Epoch : 121, training loss : 0.0069, training accuracy : 99.76, val loss : 0.5238, val accuracy : 90.97\n",
            "\n",
            "Epoch: 122\n",
            "iteration :  50, loss : 0.0102, accuracy : 99.64\n",
            "iteration : 100, loss : 0.0098, accuracy : 99.64\n",
            "iteration : 150, loss : 0.0095, accuracy : 99.63\n",
            "iteration : 200, loss : 0.0094, accuracy : 99.62\n",
            "iteration : 250, loss : 0.0091, accuracy : 99.64\n",
            "iteration : 300, loss : 0.0090, accuracy : 99.66\n",
            "Epoch : 122, training loss : 0.0091, training accuracy : 99.65, val loss : 0.4906, val accuracy : 91.40\n",
            "\n",
            "Epoch: 123\n",
            "iteration :  50, loss : 0.0107, accuracy : 99.64\n",
            "iteration : 100, loss : 0.0085, accuracy : 99.71\n",
            "iteration : 150, loss : 0.0084, accuracy : 99.72\n",
            "iteration : 200, loss : 0.0086, accuracy : 99.73\n",
            "iteration : 250, loss : 0.0094, accuracy : 99.70\n",
            "iteration : 300, loss : 0.0092, accuracy : 99.71\n",
            "Epoch : 123, training loss : 0.0091, training accuracy : 99.72, val loss : 0.5043, val accuracy : 91.18\n",
            "\n",
            "Epoch: 124\n",
            "iteration :  50, loss : 0.0080, accuracy : 99.73\n",
            "iteration : 100, loss : 0.0069, accuracy : 99.78\n",
            "iteration : 150, loss : 0.0069, accuracy : 99.78\n",
            "iteration : 200, loss : 0.0072, accuracy : 99.77\n",
            "iteration : 250, loss : 0.0071, accuracy : 99.75\n",
            "iteration : 300, loss : 0.0072, accuracy : 99.75\n",
            "Epoch : 124, training loss : 0.0074, training accuracy : 99.75, val loss : 0.5031, val accuracy : 91.19\n",
            "\n",
            "Epoch: 125\n",
            "iteration :  50, loss : 0.0081, accuracy : 99.73\n",
            "iteration : 100, loss : 0.0082, accuracy : 99.77\n",
            "iteration : 150, loss : 0.0090, accuracy : 99.72\n",
            "iteration : 200, loss : 0.0094, accuracy : 99.70\n",
            "iteration : 250, loss : 0.0093, accuracy : 99.70\n",
            "iteration : 300, loss : 0.0099, accuracy : 99.68\n",
            "Epoch : 125, training loss : 0.0100, training accuracy : 99.67, val loss : 0.5107, val accuracy : 91.16\n",
            "\n",
            "Epoch: 126\n",
            "iteration :  50, loss : 0.0052, accuracy : 99.78\n",
            "iteration : 100, loss : 0.0058, accuracy : 99.78\n",
            "iteration : 150, loss : 0.0066, accuracy : 99.75\n",
            "iteration : 200, loss : 0.0067, accuracy : 99.76\n",
            "iteration : 250, loss : 0.0067, accuracy : 99.77\n",
            "iteration : 300, loss : 0.0067, accuracy : 99.77\n",
            "Epoch : 126, training loss : 0.0066, training accuracy : 99.78, val loss : 0.5003, val accuracy : 91.24\n",
            "\n",
            "Epoch: 127\n",
            "iteration :  50, loss : 0.0065, accuracy : 99.78\n",
            "iteration : 100, loss : 0.0073, accuracy : 99.74\n",
            "iteration : 150, loss : 0.0074, accuracy : 99.73\n",
            "iteration : 200, loss : 0.0068, accuracy : 99.76\n",
            "iteration : 250, loss : 0.0065, accuracy : 99.77\n",
            "iteration : 300, loss : 0.0069, accuracy : 99.76\n",
            "Epoch : 127, training loss : 0.0069, training accuracy : 99.77, val loss : 0.5015, val accuracy : 91.45\n",
            "\n",
            "Epoch: 128\n",
            "iteration :  50, loss : 0.0068, accuracy : 99.80\n",
            "iteration : 100, loss : 0.0072, accuracy : 99.76\n",
            "iteration : 150, loss : 0.0069, accuracy : 99.77\n",
            "iteration : 200, loss : 0.0067, accuracy : 99.77\n",
            "iteration : 250, loss : 0.0065, accuracy : 99.77\n",
            "iteration : 300, loss : 0.0064, accuracy : 99.79\n",
            "Epoch : 128, training loss : 0.0062, training accuracy : 99.79, val loss : 0.4851, val accuracy : 91.62\n",
            "\n",
            "Epoch: 129\n",
            "iteration :  50, loss : 0.0048, accuracy : 99.83\n",
            "iteration : 100, loss : 0.0048, accuracy : 99.84\n",
            "iteration : 150, loss : 0.0048, accuracy : 99.86\n",
            "iteration : 200, loss : 0.0049, accuracy : 99.84\n",
            "iteration : 250, loss : 0.0051, accuracy : 99.84\n",
            "iteration : 300, loss : 0.0058, accuracy : 99.81\n",
            "Epoch : 129, training loss : 0.0059, training accuracy : 99.80, val loss : 0.5054, val accuracy : 91.18\n",
            "\n",
            "Epoch: 130\n",
            "iteration :  50, loss : 0.0060, accuracy : 99.77\n",
            "iteration : 100, loss : 0.0049, accuracy : 99.84\n",
            "iteration : 150, loss : 0.0044, accuracy : 99.85\n",
            "iteration : 200, loss : 0.0047, accuracy : 99.83\n",
            "iteration : 250, loss : 0.0046, accuracy : 99.83\n",
            "iteration : 300, loss : 0.0046, accuracy : 99.84\n",
            "Epoch : 130, training loss : 0.0046, training accuracy : 99.84, val loss : 0.4952, val accuracy : 91.76\n",
            "\n",
            "Epoch: 131\n",
            "iteration :  50, loss : 0.0042, accuracy : 99.83\n",
            "iteration : 100, loss : 0.0043, accuracy : 99.86\n",
            "iteration : 150, loss : 0.0049, accuracy : 99.84\n",
            "iteration : 200, loss : 0.0054, accuracy : 99.81\n",
            "iteration : 250, loss : 0.0053, accuracy : 99.83\n",
            "iteration : 300, loss : 0.0049, accuracy : 99.84\n",
            "Epoch : 131, training loss : 0.0049, training accuracy : 99.84, val loss : 0.4907, val accuracy : 91.45\n",
            "\n",
            "Epoch: 132\n",
            "iteration :  50, loss : 0.0033, accuracy : 99.91\n",
            "iteration : 100, loss : 0.0043, accuracy : 99.88\n",
            "iteration : 150, loss : 0.0041, accuracy : 99.88\n",
            "iteration : 200, loss : 0.0037, accuracy : 99.89\n",
            "iteration : 250, loss : 0.0038, accuracy : 99.89\n",
            "iteration : 300, loss : 0.0035, accuracy : 99.90\n",
            "Epoch : 132, training loss : 0.0034, training accuracy : 99.90, val loss : 0.4678, val accuracy : 91.56\n",
            "\n",
            "Epoch: 133\n",
            "iteration :  50, loss : 0.0036, accuracy : 99.91\n",
            "iteration : 100, loss : 0.0041, accuracy : 99.89\n",
            "iteration : 150, loss : 0.0038, accuracy : 99.91\n",
            "iteration : 200, loss : 0.0035, accuracy : 99.89\n",
            "iteration : 250, loss : 0.0039, accuracy : 99.89\n",
            "iteration : 300, loss : 0.0040, accuracy : 99.88\n",
            "Epoch : 133, training loss : 0.0039, training accuracy : 99.88, val loss : 0.5174, val accuracy : 91.47\n",
            "\n",
            "Epoch: 134\n",
            "iteration :  50, loss : 0.0039, accuracy : 99.86\n",
            "iteration : 100, loss : 0.0049, accuracy : 99.83\n",
            "iteration : 150, loss : 0.0048, accuracy : 99.81\n",
            "iteration : 200, loss : 0.0050, accuracy : 99.80\n",
            "iteration : 250, loss : 0.0052, accuracy : 99.81\n",
            "iteration : 300, loss : 0.0058, accuracy : 99.80\n",
            "Epoch : 134, training loss : 0.0057, training accuracy : 99.80, val loss : 0.5407, val accuracy : 90.81\n",
            "\n",
            "Epoch: 135\n",
            "iteration :  50, loss : 0.0143, accuracy : 99.44\n",
            "iteration : 100, loss : 0.0121, accuracy : 99.52\n",
            "iteration : 150, loss : 0.0107, accuracy : 99.59\n",
            "iteration : 200, loss : 0.0097, accuracy : 99.63\n",
            "iteration : 250, loss : 0.0089, accuracy : 99.67\n",
            "iteration : 300, loss : 0.0086, accuracy : 99.68\n",
            "Epoch : 135, training loss : 0.0087, training accuracy : 99.68, val loss : 0.4862, val accuracy : 91.52\n",
            "\n",
            "Epoch: 136\n",
            "iteration :  50, loss : 0.0066, accuracy : 99.83\n",
            "iteration : 100, loss : 0.0063, accuracy : 99.83\n",
            "iteration : 150, loss : 0.0069, accuracy : 99.81\n",
            "iteration : 200, loss : 0.0067, accuracy : 99.81\n",
            "iteration : 250, loss : 0.0065, accuracy : 99.81\n",
            "iteration : 300, loss : 0.0066, accuracy : 99.80\n",
            "Epoch : 136, training loss : 0.0068, training accuracy : 99.80, val loss : 0.5100, val accuracy : 91.16\n",
            "\n",
            "Epoch: 137\n",
            "iteration :  50, loss : 0.0056, accuracy : 99.84\n",
            "iteration : 100, loss : 0.0059, accuracy : 99.83\n",
            "iteration : 150, loss : 0.0055, accuracy : 99.81\n",
            "iteration : 200, loss : 0.0058, accuracy : 99.82\n",
            "iteration : 250, loss : 0.0056, accuracy : 99.82\n",
            "iteration : 300, loss : 0.0059, accuracy : 99.81\n",
            "Epoch : 137, training loss : 0.0058, training accuracy : 99.82, val loss : 0.5130, val accuracy : 91.28\n",
            "\n",
            "Epoch: 138\n",
            "iteration :  50, loss : 0.0044, accuracy : 99.92\n",
            "iteration : 100, loss : 0.0043, accuracy : 99.88\n",
            "iteration : 150, loss : 0.0038, accuracy : 99.89\n",
            "iteration : 200, loss : 0.0042, accuracy : 99.88\n",
            "iteration : 250, loss : 0.0044, accuracy : 99.87\n",
            "iteration : 300, loss : 0.0051, accuracy : 99.85\n",
            "Epoch : 138, training loss : 0.0051, training accuracy : 99.86, val loss : 0.5396, val accuracy : 90.85\n",
            "\n",
            "Epoch: 139\n",
            "iteration :  50, loss : 0.0042, accuracy : 99.88\n",
            "iteration : 100, loss : 0.0033, accuracy : 99.91\n",
            "iteration : 150, loss : 0.0037, accuracy : 99.91\n",
            "iteration : 200, loss : 0.0038, accuracy : 99.89\n",
            "iteration : 250, loss : 0.0035, accuracy : 99.91\n",
            "iteration : 300, loss : 0.0034, accuracy : 99.91\n",
            "Epoch : 139, training loss : 0.0034, training accuracy : 99.91, val loss : 0.5077, val accuracy : 91.37\n",
            "\n",
            "Epoch: 140\n",
            "iteration :  50, loss : 0.0033, accuracy : 99.91\n",
            "iteration : 100, loss : 0.0039, accuracy : 99.88\n",
            "iteration : 150, loss : 0.0042, accuracy : 99.86\n",
            "iteration : 200, loss : 0.0046, accuracy : 99.84\n",
            "iteration : 250, loss : 0.0052, accuracy : 99.81\n",
            "iteration : 300, loss : 0.0054, accuracy : 99.81\n",
            "Epoch : 140, training loss : 0.0057, training accuracy : 99.80, val loss : 0.5418, val accuracy : 90.73\n",
            "\n",
            "Epoch: 141\n",
            "iteration :  50, loss : 0.0077, accuracy : 99.75\n",
            "iteration : 100, loss : 0.0076, accuracy : 99.72\n",
            "iteration : 150, loss : 0.0075, accuracy : 99.74\n",
            "iteration : 200, loss : 0.0074, accuracy : 99.75\n",
            "iteration : 250, loss : 0.0073, accuracy : 99.77\n",
            "iteration : 300, loss : 0.0075, accuracy : 99.75\n",
            "Epoch : 141, training loss : 0.0076, training accuracy : 99.75, val loss : 0.5387, val accuracy : 91.07\n",
            "\n",
            "Epoch: 142\n",
            "iteration :  50, loss : 0.0084, accuracy : 99.69\n",
            "iteration : 100, loss : 0.0072, accuracy : 99.71\n",
            "iteration : 150, loss : 0.0063, accuracy : 99.74\n",
            "iteration : 200, loss : 0.0064, accuracy : 99.75\n",
            "iteration : 250, loss : 0.0071, accuracy : 99.74\n",
            "iteration : 300, loss : 0.0070, accuracy : 99.75\n",
            "Epoch : 142, training loss : 0.0070, training accuracy : 99.75, val loss : 0.4983, val accuracy : 91.50\n",
            "\n",
            "Epoch: 143\n",
            "iteration :  50, loss : 0.0056, accuracy : 99.81\n",
            "iteration : 100, loss : 0.0067, accuracy : 99.80\n",
            "iteration : 150, loss : 0.0060, accuracy : 99.82\n",
            "iteration : 200, loss : 0.0062, accuracy : 99.79\n",
            "iteration : 250, loss : 0.0063, accuracy : 99.79\n",
            "iteration : 300, loss : 0.0062, accuracy : 99.80\n",
            "Epoch : 143, training loss : 0.0063, training accuracy : 99.79, val loss : 0.5300, val accuracy : 90.99\n",
            "\n",
            "Epoch: 144\n",
            "iteration :  50, loss : 0.0087, accuracy : 99.69\n",
            "iteration : 100, loss : 0.0102, accuracy : 99.65\n",
            "iteration : 150, loss : 0.0096, accuracy : 99.68\n",
            "iteration : 200, loss : 0.0091, accuracy : 99.69\n",
            "iteration : 250, loss : 0.0084, accuracy : 99.72\n",
            "iteration : 300, loss : 0.0082, accuracy : 99.73\n",
            "Epoch : 144, training loss : 0.0082, training accuracy : 99.73, val loss : 0.5206, val accuracy : 91.12\n",
            "\n",
            "Epoch: 145\n",
            "iteration :  50, loss : 0.0053, accuracy : 99.81\n",
            "iteration : 100, loss : 0.0050, accuracy : 99.82\n",
            "iteration : 150, loss : 0.0050, accuracy : 99.82\n",
            "iteration : 200, loss : 0.0054, accuracy : 99.83\n",
            "iteration : 250, loss : 0.0058, accuracy : 99.82\n",
            "iteration : 300, loss : 0.0056, accuracy : 99.83\n",
            "Epoch : 145, training loss : 0.0055, training accuracy : 99.83, val loss : 0.5195, val accuracy : 91.40\n",
            "\n",
            "Epoch: 146\n",
            "iteration :  50, loss : 0.0045, accuracy : 99.83\n",
            "iteration : 100, loss : 0.0042, accuracy : 99.88\n",
            "iteration : 150, loss : 0.0041, accuracy : 99.88\n",
            "iteration : 200, loss : 0.0039, accuracy : 99.88\n",
            "iteration : 250, loss : 0.0041, accuracy : 99.87\n",
            "iteration : 300, loss : 0.0043, accuracy : 99.85\n",
            "Epoch : 146, training loss : 0.0043, training accuracy : 99.86, val loss : 0.5147, val accuracy : 91.23\n",
            "\n",
            "Epoch: 147\n",
            "iteration :  50, loss : 0.0030, accuracy : 99.88\n",
            "iteration : 100, loss : 0.0038, accuracy : 99.85\n",
            "iteration : 150, loss : 0.0038, accuracy : 99.85\n",
            "iteration : 200, loss : 0.0036, accuracy : 99.87\n",
            "iteration : 250, loss : 0.0035, accuracy : 99.88\n",
            "iteration : 300, loss : 0.0033, accuracy : 99.89\n",
            "Epoch : 147, training loss : 0.0036, training accuracy : 99.88, val loss : 0.4946, val accuracy : 91.63\n",
            "\n",
            "Epoch: 148\n",
            "iteration :  50, loss : 0.0030, accuracy : 99.94\n",
            "iteration : 100, loss : 0.0028, accuracy : 99.94\n",
            "iteration : 150, loss : 0.0033, accuracy : 99.91\n",
            "iteration : 200, loss : 0.0037, accuracy : 99.90\n",
            "iteration : 250, loss : 0.0042, accuracy : 99.87\n",
            "iteration : 300, loss : 0.0044, accuracy : 99.86\n",
            "Epoch : 148, training loss : 0.0043, training accuracy : 99.86, val loss : 0.5363, val accuracy : 91.30\n",
            "\n",
            "Epoch: 149\n",
            "iteration :  50, loss : 0.0050, accuracy : 99.89\n",
            "iteration : 100, loss : 0.0038, accuracy : 99.92\n",
            "iteration : 150, loss : 0.0037, accuracy : 99.90\n",
            "iteration : 200, loss : 0.0037, accuracy : 99.90\n",
            "iteration : 250, loss : 0.0042, accuracy : 99.88\n",
            "iteration : 300, loss : 0.0046, accuracy : 99.86\n",
            "Epoch : 149, training loss : 0.0045, training accuracy : 99.86, val loss : 0.5109, val accuracy : 91.74\n",
            "\n",
            "Epoch: 150\n",
            "iteration :  50, loss : 0.0047, accuracy : 99.84\n",
            "iteration : 100, loss : 0.0054, accuracy : 99.82\n",
            "iteration : 150, loss : 0.0055, accuracy : 99.81\n",
            "iteration : 200, loss : 0.0057, accuracy : 99.81\n",
            "iteration : 250, loss : 0.0059, accuracy : 99.80\n",
            "iteration : 300, loss : 0.0062, accuracy : 99.79\n",
            "Epoch : 150, training loss : 0.0061, training accuracy : 99.80, val loss : 0.5464, val accuracy : 91.24\n",
            "\n",
            "Epoch: 151\n",
            "iteration :  50, loss : 0.0080, accuracy : 99.72\n",
            "iteration : 100, loss : 0.0074, accuracy : 99.69\n",
            "iteration : 150, loss : 0.0063, accuracy : 99.76\n",
            "iteration : 200, loss : 0.0058, accuracy : 99.79\n",
            "iteration : 250, loss : 0.0056, accuracy : 99.80\n",
            "iteration : 300, loss : 0.0054, accuracy : 99.82\n",
            "Epoch : 151, training loss : 0.0055, training accuracy : 99.81, val loss : 0.5191, val accuracy : 91.49\n",
            "\n",
            "Epoch: 152\n",
            "iteration :  50, loss : 0.0058, accuracy : 99.84\n",
            "iteration : 100, loss : 0.0049, accuracy : 99.89\n",
            "iteration : 150, loss : 0.0041, accuracy : 99.90\n",
            "iteration : 200, loss : 0.0043, accuracy : 99.87\n",
            "iteration : 250, loss : 0.0046, accuracy : 99.86\n",
            "iteration : 300, loss : 0.0051, accuracy : 99.84\n",
            "Epoch : 152, training loss : 0.0053, training accuracy : 99.83, val loss : 0.5412, val accuracy : 91.61\n",
            "\n",
            "Epoch: 153\n",
            "iteration :  50, loss : 0.0077, accuracy : 99.77\n",
            "iteration : 100, loss : 0.0087, accuracy : 99.71\n",
            "iteration : 150, loss : 0.0073, accuracy : 99.77\n",
            "iteration : 200, loss : 0.0062, accuracy : 99.80\n",
            "iteration : 250, loss : 0.0055, accuracy : 99.83\n",
            "iteration : 300, loss : 0.0052, accuracy : 99.83\n",
            "Epoch : 153, training loss : 0.0052, training accuracy : 99.83, val loss : 0.5007, val accuracy : 91.27\n",
            "\n",
            "Epoch: 154\n",
            "iteration :  50, loss : 0.0032, accuracy : 99.92\n",
            "iteration : 100, loss : 0.0026, accuracy : 99.94\n",
            "iteration : 150, loss : 0.0029, accuracy : 99.92\n",
            "iteration : 200, loss : 0.0032, accuracy : 99.91\n",
            "iteration : 250, loss : 0.0032, accuracy : 99.90\n",
            "iteration : 300, loss : 0.0037, accuracy : 99.89\n",
            "Epoch : 154, training loss : 0.0039, training accuracy : 99.88, val loss : 0.5196, val accuracy : 91.49\n",
            "\n",
            "Epoch: 155\n",
            "iteration :  50, loss : 0.0052, accuracy : 99.78\n",
            "iteration : 100, loss : 0.0065, accuracy : 99.77\n",
            "iteration : 150, loss : 0.0064, accuracy : 99.77\n",
            "iteration : 200, loss : 0.0067, accuracy : 99.76\n",
            "iteration : 250, loss : 0.0074, accuracy : 99.75\n",
            "iteration : 300, loss : 0.0081, accuracy : 99.72\n",
            "Epoch : 155, training loss : 0.0079, training accuracy : 99.73, val loss : 0.5699, val accuracy : 90.54\n",
            "\n",
            "Epoch: 156\n",
            "iteration :  50, loss : 0.0097, accuracy : 99.67\n",
            "iteration : 100, loss : 0.0083, accuracy : 99.75\n",
            "iteration : 150, loss : 0.0087, accuracy : 99.73\n",
            "iteration : 200, loss : 0.0080, accuracy : 99.74\n",
            "iteration : 250, loss : 0.0073, accuracy : 99.76\n",
            "iteration : 300, loss : 0.0070, accuracy : 99.78\n",
            "Epoch : 156, training loss : 0.0069, training accuracy : 99.78, val loss : 0.5143, val accuracy : 91.18\n",
            "\n",
            "Epoch: 157\n",
            "iteration :  50, loss : 0.0042, accuracy : 99.81\n",
            "iteration : 100, loss : 0.0051, accuracy : 99.79\n",
            "iteration : 150, loss : 0.0051, accuracy : 99.80\n",
            "iteration : 200, loss : 0.0053, accuracy : 99.80\n",
            "iteration : 250, loss : 0.0050, accuracy : 99.82\n",
            "iteration : 300, loss : 0.0050, accuracy : 99.82\n",
            "Epoch : 157, training loss : 0.0050, training accuracy : 99.82, val loss : 0.5273, val accuracy : 91.14\n",
            "\n",
            "Epoch: 158\n",
            "iteration :  50, loss : 0.0065, accuracy : 99.81\n",
            "iteration : 100, loss : 0.0076, accuracy : 99.75\n",
            "iteration : 150, loss : 0.0092, accuracy : 99.72\n",
            "iteration : 200, loss : 0.0087, accuracy : 99.74\n",
            "iteration : 250, loss : 0.0078, accuracy : 99.76\n",
            "iteration : 300, loss : 0.0074, accuracy : 99.77\n",
            "Epoch : 158, training loss : 0.0074, training accuracy : 99.76, val loss : 0.5162, val accuracy : 91.21\n",
            "\n",
            "Epoch: 159\n",
            "iteration :  50, loss : 0.0051, accuracy : 99.84\n",
            "iteration : 100, loss : 0.0054, accuracy : 99.80\n",
            "iteration : 150, loss : 0.0049, accuracy : 99.83\n",
            "iteration : 200, loss : 0.0045, accuracy : 99.85\n",
            "iteration : 250, loss : 0.0047, accuracy : 99.83\n",
            "iteration : 300, loss : 0.0046, accuracy : 99.85\n",
            "Epoch : 159, training loss : 0.0045, training accuracy : 99.85, val loss : 0.5221, val accuracy : 91.71\n",
            "\n",
            "Epoch: 160\n",
            "iteration :  50, loss : 0.0040, accuracy : 99.91\n",
            "iteration : 100, loss : 0.0035, accuracy : 99.91\n",
            "iteration : 150, loss : 0.0037, accuracy : 99.89\n",
            "iteration : 200, loss : 0.0039, accuracy : 99.88\n",
            "iteration : 250, loss : 0.0047, accuracy : 99.84\n",
            "iteration : 300, loss : 0.0050, accuracy : 99.82\n",
            "Epoch : 160, training loss : 0.0051, training accuracy : 99.82, val loss : 0.5234, val accuracy : 91.14\n",
            "\n",
            "Epoch: 161\n",
            "iteration :  50, loss : 0.0052, accuracy : 99.86\n",
            "iteration : 100, loss : 0.0051, accuracy : 99.85\n",
            "iteration : 150, loss : 0.0043, accuracy : 99.88\n",
            "iteration : 200, loss : 0.0046, accuracy : 99.87\n",
            "iteration : 250, loss : 0.0047, accuracy : 99.87\n",
            "iteration : 300, loss : 0.0045, accuracy : 99.86\n",
            "Epoch : 161, training loss : 0.0045, training accuracy : 99.86, val loss : 0.5219, val accuracy : 91.41\n",
            "\n",
            "Epoch: 162\n",
            "iteration :  50, loss : 0.0036, accuracy : 99.92\n",
            "iteration : 100, loss : 0.0033, accuracy : 99.90\n",
            "iteration : 150, loss : 0.0034, accuracy : 99.90\n",
            "iteration : 200, loss : 0.0036, accuracy : 99.89\n",
            "iteration : 250, loss : 0.0040, accuracy : 99.88\n",
            "iteration : 300, loss : 0.0042, accuracy : 99.87\n",
            "Epoch : 162, training loss : 0.0043, training accuracy : 99.87, val loss : 0.5411, val accuracy : 91.29\n",
            "\n",
            "Epoch: 163\n",
            "iteration :  50, loss : 0.0050, accuracy : 99.84\n",
            "iteration : 100, loss : 0.0046, accuracy : 99.86\n",
            "iteration : 150, loss : 0.0048, accuracy : 99.84\n",
            "iteration : 200, loss : 0.0056, accuracy : 99.79\n",
            "iteration : 250, loss : 0.0053, accuracy : 99.80\n",
            "iteration : 300, loss : 0.0050, accuracy : 99.81\n",
            "Epoch : 163, training loss : 0.0051, training accuracy : 99.81, val loss : 0.5520, val accuracy : 91.06\n",
            "\n",
            "Epoch: 164\n",
            "iteration :  50, loss : 0.0057, accuracy : 99.80\n",
            "iteration : 100, loss : 0.0048, accuracy : 99.87\n",
            "iteration : 150, loss : 0.0042, accuracy : 99.88\n",
            "iteration : 200, loss : 0.0043, accuracy : 99.87\n",
            "iteration : 250, loss : 0.0047, accuracy : 99.84\n",
            "iteration : 300, loss : 0.0049, accuracy : 99.85\n",
            "Epoch : 164, training loss : 0.0049, training accuracy : 99.85, val loss : 0.4896, val accuracy : 91.69\n",
            "\n",
            "Epoch: 165\n",
            "iteration :  50, loss : 0.0026, accuracy : 99.95\n",
            "iteration : 100, loss : 0.0032, accuracy : 99.92\n",
            "iteration : 150, loss : 0.0040, accuracy : 99.90\n",
            "iteration : 200, loss : 0.0039, accuracy : 99.89\n",
            "iteration : 250, loss : 0.0039, accuracy : 99.89\n",
            "iteration : 300, loss : 0.0037, accuracy : 99.89\n",
            "Epoch : 165, training loss : 0.0037, training accuracy : 99.89, val loss : 0.5244, val accuracy : 91.56\n",
            "\n",
            "Epoch: 166\n",
            "iteration :  50, loss : 0.0031, accuracy : 99.94\n",
            "iteration : 100, loss : 0.0028, accuracy : 99.92\n",
            "iteration : 150, loss : 0.0032, accuracy : 99.92\n",
            "iteration : 200, loss : 0.0032, accuracy : 99.91\n",
            "iteration : 250, loss : 0.0035, accuracy : 99.89\n",
            "iteration : 300, loss : 0.0037, accuracy : 99.88\n",
            "Epoch : 166, training loss : 0.0037, training accuracy : 99.89, val loss : 0.5417, val accuracy : 91.25\n",
            "\n",
            "Epoch: 167\n",
            "iteration :  50, loss : 0.0043, accuracy : 99.89\n",
            "iteration : 100, loss : 0.0031, accuracy : 99.91\n",
            "iteration : 150, loss : 0.0028, accuracy : 99.92\n",
            "iteration : 200, loss : 0.0027, accuracy : 99.92\n",
            "iteration : 250, loss : 0.0029, accuracy : 99.91\n",
            "iteration : 300, loss : 0.0029, accuracy : 99.91\n",
            "Epoch : 167, training loss : 0.0030, training accuracy : 99.91, val loss : 0.5131, val accuracy : 91.38\n",
            "\n",
            "Epoch: 168\n",
            "iteration :  50, loss : 0.0022, accuracy : 99.94\n",
            "iteration : 100, loss : 0.0028, accuracy : 99.92\n",
            "iteration : 150, loss : 0.0027, accuracy : 99.92\n",
            "iteration : 200, loss : 0.0027, accuracy : 99.91\n",
            "iteration : 250, loss : 0.0028, accuracy : 99.91\n",
            "iteration : 300, loss : 0.0031, accuracy : 99.90\n",
            "Epoch : 168, training loss : 0.0030, training accuracy : 99.90, val loss : 0.5209, val accuracy : 91.57\n",
            "\n",
            "Epoch: 169\n",
            "iteration :  50, loss : 0.0032, accuracy : 99.91\n",
            "iteration : 100, loss : 0.0028, accuracy : 99.92\n",
            "iteration : 150, loss : 0.0025, accuracy : 99.94\n",
            "iteration : 200, loss : 0.0024, accuracy : 99.95\n",
            "iteration : 250, loss : 0.0027, accuracy : 99.94\n",
            "iteration : 300, loss : 0.0027, accuracy : 99.93\n",
            "Epoch : 169, training loss : 0.0028, training accuracy : 99.93, val loss : 0.5355, val accuracy : 91.38\n",
            "\n",
            "Epoch: 170\n",
            "iteration :  50, loss : 0.0070, accuracy : 99.78\n",
            "iteration : 100, loss : 0.0066, accuracy : 99.80\n",
            "iteration : 150, loss : 0.0052, accuracy : 99.84\n",
            "iteration : 200, loss : 0.0045, accuracy : 99.87\n",
            "iteration : 250, loss : 0.0041, accuracy : 99.88\n",
            "iteration : 300, loss : 0.0039, accuracy : 99.89\n",
            "Epoch : 170, training loss : 0.0038, training accuracy : 99.89, val loss : 0.5360, val accuracy : 91.49\n",
            "\n",
            "Epoch: 171\n",
            "iteration :  50, loss : 0.0048, accuracy : 99.80\n",
            "iteration : 100, loss : 0.0031, accuracy : 99.88\n",
            "iteration : 150, loss : 0.0032, accuracy : 99.88\n",
            "iteration : 200, loss : 0.0035, accuracy : 99.87\n",
            "iteration : 250, loss : 0.0039, accuracy : 99.86\n",
            "iteration : 300, loss : 0.0037, accuracy : 99.87\n",
            "Epoch : 171, training loss : 0.0039, training accuracy : 99.86, val loss : 0.5215, val accuracy : 91.42\n",
            "\n",
            "Epoch: 172\n",
            "iteration :  50, loss : 0.0030, accuracy : 99.89\n",
            "iteration : 100, loss : 0.0042, accuracy : 99.88\n",
            "iteration : 150, loss : 0.0048, accuracy : 99.84\n",
            "iteration : 200, loss : 0.0051, accuracy : 99.82\n",
            "iteration : 250, loss : 0.0055, accuracy : 99.81\n",
            "iteration : 300, loss : 0.0054, accuracy : 99.82\n",
            "Epoch : 172, training loss : 0.0055, training accuracy : 99.81, val loss : 0.5138, val accuracy : 91.38\n",
            "\n",
            "Epoch: 173\n",
            "iteration :  50, loss : 0.0081, accuracy : 99.77\n",
            "iteration : 100, loss : 0.0063, accuracy : 99.81\n",
            "iteration : 150, loss : 0.0059, accuracy : 99.81\n",
            "iteration : 200, loss : 0.0054, accuracy : 99.81\n",
            "iteration : 250, loss : 0.0053, accuracy : 99.81\n",
            "iteration : 300, loss : 0.0049, accuracy : 99.82\n",
            "Epoch : 173, training loss : 0.0049, training accuracy : 99.82, val loss : 0.5302, val accuracy : 91.04\n",
            "\n",
            "Epoch: 174\n",
            "iteration :  50, loss : 0.0040, accuracy : 99.86\n",
            "iteration : 100, loss : 0.0053, accuracy : 99.77\n",
            "iteration : 150, loss : 0.0054, accuracy : 99.78\n",
            "iteration : 200, loss : 0.0051, accuracy : 99.81\n",
            "iteration : 250, loss : 0.0046, accuracy : 99.83\n",
            "iteration : 300, loss : 0.0041, accuracy : 99.84\n",
            "Epoch : 174, training loss : 0.0041, training accuracy : 99.85, val loss : 0.5084, val accuracy : 91.62\n",
            "\n",
            "Epoch: 175\n",
            "iteration :  50, loss : 0.0046, accuracy : 99.84\n",
            "iteration : 100, loss : 0.0062, accuracy : 99.79\n",
            "iteration : 150, loss : 0.0055, accuracy : 99.80\n",
            "iteration : 200, loss : 0.0049, accuracy : 99.83\n",
            "iteration : 250, loss : 0.0046, accuracy : 99.84\n",
            "iteration : 300, loss : 0.0045, accuracy : 99.85\n",
            "Epoch : 175, training loss : 0.0044, training accuracy : 99.85, val loss : 0.5410, val accuracy : 90.94\n",
            "\n",
            "Epoch: 176\n",
            "iteration :  50, loss : 0.0048, accuracy : 99.78\n",
            "iteration : 100, loss : 0.0036, accuracy : 99.84\n",
            "iteration : 150, loss : 0.0039, accuracy : 99.84\n",
            "iteration : 200, loss : 0.0035, accuracy : 99.87\n",
            "iteration : 250, loss : 0.0034, accuracy : 99.87\n",
            "iteration : 300, loss : 0.0034, accuracy : 99.86\n",
            "Epoch : 176, training loss : 0.0035, training accuracy : 99.86, val loss : 0.5577, val accuracy : 90.94\n",
            "\n",
            "Epoch: 177\n",
            "iteration :  50, loss : 0.0062, accuracy : 99.78\n",
            "iteration : 100, loss : 0.0055, accuracy : 99.80\n",
            "iteration : 150, loss : 0.0053, accuracy : 99.81\n",
            "iteration : 200, loss : 0.0051, accuracy : 99.82\n",
            "iteration : 250, loss : 0.0048, accuracy : 99.83\n",
            "iteration : 300, loss : 0.0043, accuracy : 99.85\n",
            "Epoch : 177, training loss : 0.0042, training accuracy : 99.86, val loss : 0.5107, val accuracy : 91.57\n",
            "\n",
            "Epoch: 178\n",
            "iteration :  50, loss : 0.0017, accuracy : 99.95\n",
            "iteration : 100, loss : 0.0022, accuracy : 99.94\n",
            "iteration : 150, loss : 0.0027, accuracy : 99.91\n",
            "iteration : 200, loss : 0.0033, accuracy : 99.89\n",
            "iteration : 250, loss : 0.0035, accuracy : 99.89\n",
            "iteration : 300, loss : 0.0036, accuracy : 99.88\n",
            "Epoch : 178, training loss : 0.0037, training accuracy : 99.88, val loss : 0.5364, val accuracy : 91.24\n",
            "\n",
            "Epoch: 179\n",
            "iteration :  50, loss : 0.0038, accuracy : 99.88\n",
            "iteration : 100, loss : 0.0032, accuracy : 99.88\n",
            "iteration : 150, loss : 0.0031, accuracy : 99.90\n",
            "iteration : 200, loss : 0.0029, accuracy : 99.91\n",
            "iteration : 250, loss : 0.0033, accuracy : 99.89\n",
            "iteration : 300, loss : 0.0035, accuracy : 99.89\n",
            "Epoch : 179, training loss : 0.0035, training accuracy : 99.89, val loss : 0.5152, val accuracy : 91.43\n",
            "\n",
            "Epoch: 180\n",
            "iteration :  50, loss : 0.0048, accuracy : 99.81\n",
            "iteration : 100, loss : 0.0036, accuracy : 99.87\n",
            "iteration : 150, loss : 0.0036, accuracy : 99.88\n",
            "iteration : 200, loss : 0.0037, accuracy : 99.87\n",
            "iteration : 250, loss : 0.0039, accuracy : 99.87\n",
            "iteration : 300, loss : 0.0038, accuracy : 99.88\n",
            "Epoch : 180, training loss : 0.0037, training accuracy : 99.89, val loss : 0.5335, val accuracy : 91.27\n",
            "\n",
            "Epoch: 181\n",
            "iteration :  50, loss : 0.0025, accuracy : 99.92\n",
            "iteration : 100, loss : 0.0036, accuracy : 99.91\n",
            "iteration : 150, loss : 0.0036, accuracy : 99.91\n",
            "iteration : 200, loss : 0.0032, accuracy : 99.92\n",
            "iteration : 250, loss : 0.0030, accuracy : 99.92\n",
            "iteration : 300, loss : 0.0028, accuracy : 99.92\n",
            "Epoch : 181, training loss : 0.0028, training accuracy : 99.92, val loss : 0.5178, val accuracy : 91.56\n",
            "\n",
            "Epoch: 182\n",
            "iteration :  50, loss : 0.0014, accuracy : 99.95\n",
            "iteration : 100, loss : 0.0012, accuracy : 99.97\n",
            "iteration : 150, loss : 0.0019, accuracy : 99.94\n",
            "iteration : 200, loss : 0.0018, accuracy : 99.95\n",
            "iteration : 250, loss : 0.0018, accuracy : 99.95\n",
            "iteration : 300, loss : 0.0020, accuracy : 99.95\n",
            "Epoch : 182, training loss : 0.0020, training accuracy : 99.95, val loss : 0.5035, val accuracy : 91.68\n",
            "\n",
            "Epoch: 183\n",
            "iteration :  50, loss : 0.0014, accuracy : 99.98\n",
            "iteration : 100, loss : 0.0015, accuracy : 99.97\n",
            "iteration : 150, loss : 0.0014, accuracy : 99.97\n",
            "iteration : 200, loss : 0.0013, accuracy : 99.97\n",
            "iteration : 250, loss : 0.0013, accuracy : 99.97\n",
            "iteration : 300, loss : 0.0012, accuracy : 99.97\n",
            "Epoch : 183, training loss : 0.0012, training accuracy : 99.97, val loss : 0.5056, val accuracy : 91.42\n",
            "\n",
            "Epoch: 184\n",
            "iteration :  50, loss : 0.0007, accuracy : 100.00\n",
            "iteration : 100, loss : 0.0019, accuracy : 99.95\n",
            "iteration : 150, loss : 0.0017, accuracy : 99.96\n",
            "iteration : 200, loss : 0.0017, accuracy : 99.96\n",
            "iteration : 250, loss : 0.0018, accuracy : 99.96\n",
            "iteration : 300, loss : 0.0018, accuracy : 99.95\n",
            "Epoch : 184, training loss : 0.0018, training accuracy : 99.95, val loss : 0.5049, val accuracy : 91.71\n",
            "\n",
            "Epoch: 185\n",
            "iteration :  50, loss : 0.0017, accuracy : 99.91\n",
            "iteration : 100, loss : 0.0016, accuracy : 99.93\n",
            "iteration : 150, loss : 0.0020, accuracy : 99.91\n",
            "iteration : 200, loss : 0.0022, accuracy : 99.90\n",
            "iteration : 250, loss : 0.0022, accuracy : 99.91\n",
            "iteration : 300, loss : 0.0021, accuracy : 99.92\n",
            "Epoch : 185, training loss : 0.0022, training accuracy : 99.91, val loss : 0.5444, val accuracy : 91.51\n",
            "\n",
            "Epoch: 186\n",
            "iteration :  50, loss : 0.0022, accuracy : 99.92\n",
            "iteration : 100, loss : 0.0022, accuracy : 99.93\n",
            "iteration : 150, loss : 0.0030, accuracy : 99.91\n",
            "iteration : 200, loss : 0.0033, accuracy : 99.89\n",
            "iteration : 250, loss : 0.0031, accuracy : 99.89\n",
            "iteration : 300, loss : 0.0028, accuracy : 99.90\n",
            "Epoch : 186, training loss : 0.0028, training accuracy : 99.91, val loss : 0.5143, val accuracy : 91.46\n",
            "\n",
            "Epoch: 187\n",
            "iteration :  50, loss : 0.0031, accuracy : 99.91\n",
            "iteration : 100, loss : 0.0031, accuracy : 99.92\n",
            "iteration : 150, loss : 0.0024, accuracy : 99.94\n",
            "iteration : 200, loss : 0.0021, accuracy : 99.95\n",
            "iteration : 250, loss : 0.0021, accuracy : 99.95\n",
            "iteration : 300, loss : 0.0020, accuracy : 99.95\n",
            "Epoch : 187, training loss : 0.0021, training accuracy : 99.95, val loss : 0.5176, val accuracy : 91.63\n",
            "\n",
            "Epoch: 188\n",
            "iteration :  50, loss : 0.0024, accuracy : 99.91\n",
            "iteration : 100, loss : 0.0027, accuracy : 99.92\n",
            "iteration : 150, loss : 0.0025, accuracy : 99.93\n",
            "iteration : 200, loss : 0.0023, accuracy : 99.93\n",
            "iteration : 250, loss : 0.0022, accuracy : 99.93\n",
            "iteration : 300, loss : 0.0021, accuracy : 99.94\n",
            "Epoch : 188, training loss : 0.0020, training accuracy : 99.94, val loss : 0.5062, val accuracy : 91.79\n",
            "\n",
            "Epoch: 189\n",
            "iteration :  50, loss : 0.0012, accuracy : 99.95\n",
            "iteration : 100, loss : 0.0012, accuracy : 99.97\n",
            "iteration : 150, loss : 0.0015, accuracy : 99.96\n",
            "iteration : 200, loss : 0.0017, accuracy : 99.96\n",
            "iteration : 250, loss : 0.0018, accuracy : 99.95\n",
            "iteration : 300, loss : 0.0020, accuracy : 99.94\n",
            "Epoch : 189, training loss : 0.0020, training accuracy : 99.94, val loss : 0.5514, val accuracy : 91.36\n",
            "\n",
            "Epoch: 190\n",
            "iteration :  50, loss : 0.0020, accuracy : 99.95\n",
            "iteration : 100, loss : 0.0022, accuracy : 99.92\n",
            "iteration : 150, loss : 0.0022, accuracy : 99.93\n",
            "iteration : 200, loss : 0.0023, accuracy : 99.93\n",
            "iteration : 250, loss : 0.0023, accuracy : 99.92\n",
            "iteration : 300, loss : 0.0025, accuracy : 99.92\n",
            "Epoch : 190, training loss : 0.0026, training accuracy : 99.92, val loss : 0.5103, val accuracy : 91.75\n",
            "\n",
            "Epoch: 191\n",
            "iteration :  50, loss : 0.0033, accuracy : 99.91\n",
            "iteration : 100, loss : 0.0025, accuracy : 99.93\n",
            "iteration : 150, loss : 0.0023, accuracy : 99.94\n",
            "iteration : 200, loss : 0.0024, accuracy : 99.93\n",
            "iteration : 250, loss : 0.0032, accuracy : 99.92\n",
            "iteration : 300, loss : 0.0035, accuracy : 99.90\n",
            "Epoch : 191, training loss : 0.0035, training accuracy : 99.90, val loss : 0.5621, val accuracy : 91.05\n",
            "\n",
            "Epoch: 192\n",
            "iteration :  50, loss : 0.0039, accuracy : 99.88\n",
            "iteration : 100, loss : 0.0039, accuracy : 99.88\n",
            "iteration : 150, loss : 0.0038, accuracy : 99.88\n",
            "iteration : 200, loss : 0.0040, accuracy : 99.87\n",
            "iteration : 250, loss : 0.0042, accuracy : 99.86\n",
            "iteration : 300, loss : 0.0047, accuracy : 99.84\n",
            "Epoch : 192, training loss : 0.0050, training accuracy : 99.83, val loss : 0.5980, val accuracy : 91.11\n",
            "\n",
            "Epoch: 193\n",
            "iteration :  50, loss : 0.0065, accuracy : 99.80\n",
            "iteration : 100, loss : 0.0071, accuracy : 99.75\n",
            "iteration : 150, loss : 0.0070, accuracy : 99.76\n",
            "iteration : 200, loss : 0.0063, accuracy : 99.79\n",
            "iteration : 250, loss : 0.0066, accuracy : 99.77\n",
            "iteration : 300, loss : 0.0065, accuracy : 99.78\n",
            "Epoch : 193, training loss : 0.0067, training accuracy : 99.77, val loss : 0.5568, val accuracy : 91.16\n",
            "\n",
            "Epoch: 194\n",
            "iteration :  50, loss : 0.0086, accuracy : 99.69\n",
            "iteration : 100, loss : 0.0065, accuracy : 99.77\n",
            "iteration : 150, loss : 0.0055, accuracy : 99.81\n",
            "iteration : 200, loss : 0.0054, accuracy : 99.82\n",
            "iteration : 250, loss : 0.0054, accuracy : 99.83\n",
            "iteration : 300, loss : 0.0057, accuracy : 99.82\n",
            "Epoch : 194, training loss : 0.0059, training accuracy : 99.81, val loss : 0.5554, val accuracy : 91.24\n",
            "\n",
            "Epoch: 195\n",
            "iteration :  50, loss : 0.0053, accuracy : 99.80\n",
            "iteration : 100, loss : 0.0057, accuracy : 99.79\n",
            "iteration : 150, loss : 0.0053, accuracy : 99.79\n",
            "iteration : 200, loss : 0.0054, accuracy : 99.79\n",
            "iteration : 250, loss : 0.0050, accuracy : 99.80\n",
            "iteration : 300, loss : 0.0059, accuracy : 99.77\n",
            "Epoch : 195, training loss : 0.0057, training accuracy : 99.78, val loss : 0.5349, val accuracy : 91.19\n",
            "\n",
            "Epoch: 196\n",
            "iteration :  50, loss : 0.0055, accuracy : 99.78\n",
            "iteration : 100, loss : 0.0047, accuracy : 99.82\n",
            "iteration : 150, loss : 0.0044, accuracy : 99.85\n",
            "iteration : 200, loss : 0.0048, accuracy : 99.85\n",
            "iteration : 250, loss : 0.0052, accuracy : 99.84\n",
            "iteration : 300, loss : 0.0053, accuracy : 99.84\n",
            "Epoch : 196, training loss : 0.0051, training accuracy : 99.84, val loss : 0.5371, val accuracy : 91.01\n",
            "\n",
            "Epoch: 197\n",
            "iteration :  50, loss : 0.0038, accuracy : 99.89\n",
            "iteration : 100, loss : 0.0040, accuracy : 99.87\n",
            "iteration : 150, loss : 0.0056, accuracy : 99.82\n",
            "iteration : 200, loss : 0.0058, accuracy : 99.82\n",
            "iteration : 250, loss : 0.0053, accuracy : 99.84\n",
            "iteration : 300, loss : 0.0051, accuracy : 99.84\n",
            "Epoch : 197, training loss : 0.0049, training accuracy : 99.85, val loss : 0.5124, val accuracy : 91.37\n",
            "\n",
            "Epoch: 198\n",
            "iteration :  50, loss : 0.0025, accuracy : 99.94\n",
            "iteration : 100, loss : 0.0020, accuracy : 99.95\n",
            "iteration : 150, loss : 0.0022, accuracy : 99.93\n",
            "iteration : 200, loss : 0.0024, accuracy : 99.93\n",
            "iteration : 250, loss : 0.0029, accuracy : 99.91\n",
            "iteration : 300, loss : 0.0035, accuracy : 99.90\n",
            "Epoch : 198, training loss : 0.0035, training accuracy : 99.89, val loss : 0.5197, val accuracy : 91.52\n",
            "\n",
            "Epoch: 199\n",
            "iteration :  50, loss : 0.0036, accuracy : 99.86\n",
            "iteration : 100, loss : 0.0038, accuracy : 99.87\n",
            "iteration : 150, loss : 0.0034, accuracy : 99.88\n",
            "iteration : 200, loss : 0.0037, accuracy : 99.88\n",
            "iteration : 250, loss : 0.0033, accuracy : 99.90\n",
            "iteration : 300, loss : 0.0031, accuracy : 99.90\n",
            "Epoch : 199, training loss : 0.0031, training accuracy : 99.90, val loss : 0.5225, val accuracy : 91.65\n",
            "\n",
            "Epoch: 200\n",
            "iteration :  50, loss : 0.0027, accuracy : 99.94\n",
            "iteration : 100, loss : 0.0025, accuracy : 99.95\n",
            "iteration : 150, loss : 0.0026, accuracy : 99.94\n",
            "iteration : 200, loss : 0.0026, accuracy : 99.94\n",
            "iteration : 250, loss : 0.0025, accuracy : 99.93\n",
            "iteration : 300, loss : 0.0024, accuracy : 99.94\n",
            "Epoch : 200, training loss : 0.0024, training accuracy : 99.94, val loss : 0.5119, val accuracy : 91.71\n",
            "\n",
            "Epoch: 201\n",
            "iteration :  50, loss : 0.0011, accuracy : 99.97\n",
            "iteration : 100, loss : 0.0022, accuracy : 99.95\n",
            "iteration : 150, loss : 0.0022, accuracy : 99.96\n",
            "iteration : 200, loss : 0.0019, accuracy : 99.96\n",
            "iteration : 250, loss : 0.0019, accuracy : 99.96\n",
            "iteration : 300, loss : 0.0019, accuracy : 99.96\n",
            "Epoch : 201, training loss : 0.0019, training accuracy : 99.96, val loss : 0.5099, val accuracy : 91.98\n",
            "\n",
            "Epoch: 202\n",
            "iteration :  50, loss : 0.0012, accuracy : 99.97\n",
            "iteration : 100, loss : 0.0012, accuracy : 99.95\n",
            "iteration : 150, loss : 0.0013, accuracy : 99.95\n",
            "iteration : 200, loss : 0.0013, accuracy : 99.95\n",
            "iteration : 250, loss : 0.0015, accuracy : 99.94\n",
            "iteration : 300, loss : 0.0017, accuracy : 99.93\n",
            "Epoch : 202, training loss : 0.0017, training accuracy : 99.94, val loss : 0.5171, val accuracy : 91.76\n",
            "\n",
            "Epoch: 203\n",
            "iteration :  50, loss : 0.0008, accuracy : 100.00\n",
            "iteration : 100, loss : 0.0008, accuracy : 99.98\n",
            "iteration : 150, loss : 0.0013, accuracy : 99.97\n",
            "iteration : 200, loss : 0.0012, accuracy : 99.98\n",
            "iteration : 250, loss : 0.0016, accuracy : 99.97\n",
            "iteration : 300, loss : 0.0015, accuracy : 99.97\n",
            "Epoch : 203, training loss : 0.0015, training accuracy : 99.97, val loss : 0.5236, val accuracy : 91.57\n",
            "\n",
            "Epoch: 204\n",
            "iteration :  50, loss : 0.0014, accuracy : 99.97\n",
            "iteration : 100, loss : 0.0015, accuracy : 99.97\n",
            "iteration : 150, loss : 0.0017, accuracy : 99.96\n",
            "iteration : 200, loss : 0.0015, accuracy : 99.96\n",
            "iteration : 250, loss : 0.0015, accuracy : 99.96\n",
            "iteration : 300, loss : 0.0015, accuracy : 99.96\n",
            "Epoch : 204, training loss : 0.0015, training accuracy : 99.96, val loss : 0.5207, val accuracy : 91.81\n",
            "\n",
            "Epoch: 205\n",
            "iteration :  50, loss : 0.0010, accuracy : 99.97\n",
            "iteration : 100, loss : 0.0012, accuracy : 99.96\n",
            "iteration : 150, loss : 0.0015, accuracy : 99.95\n",
            "iteration : 200, loss : 0.0016, accuracy : 99.95\n",
            "iteration : 250, loss : 0.0019, accuracy : 99.94\n",
            "iteration : 300, loss : 0.0022, accuracy : 99.93\n",
            "Epoch : 205, training loss : 0.0022, training accuracy : 99.94, val loss : 0.5302, val accuracy : 91.58\n",
            "\n",
            "Epoch: 206\n",
            "iteration :  50, loss : 0.0017, accuracy : 99.94\n",
            "iteration : 100, loss : 0.0017, accuracy : 99.95\n",
            "iteration : 150, loss : 0.0019, accuracy : 99.94\n",
            "iteration : 200, loss : 0.0018, accuracy : 99.94\n",
            "iteration : 250, loss : 0.0018, accuracy : 99.94\n",
            "iteration : 300, loss : 0.0018, accuracy : 99.95\n",
            "Epoch : 206, training loss : 0.0017, training accuracy : 99.95, val loss : 0.5213, val accuracy : 91.47\n",
            "\n",
            "Epoch: 207\n",
            "iteration :  50, loss : 0.0015, accuracy : 99.92\n",
            "iteration : 100, loss : 0.0013, accuracy : 99.96\n",
            "iteration : 150, loss : 0.0012, accuracy : 99.96\n",
            "iteration : 200, loss : 0.0011, accuracy : 99.96\n",
            "iteration : 250, loss : 0.0011, accuracy : 99.96\n",
            "iteration : 300, loss : 0.0011, accuracy : 99.96\n",
            "Epoch : 207, training loss : 0.0011, training accuracy : 99.96, val loss : 0.5256, val accuracy : 91.54\n",
            "\n",
            "Epoch: 208\n",
            "iteration :  50, loss : 0.0009, accuracy : 100.00\n",
            "iteration : 100, loss : 0.0010, accuracy : 99.97\n",
            "iteration : 150, loss : 0.0013, accuracy : 99.95\n",
            "iteration : 200, loss : 0.0013, accuracy : 99.95\n",
            "iteration : 250, loss : 0.0013, accuracy : 99.96\n",
            "iteration : 300, loss : 0.0012, accuracy : 99.96\n",
            "Epoch : 208, training loss : 0.0012, training accuracy : 99.96, val loss : 0.4882, val accuracy : 92.17\n",
            "\n",
            "Epoch: 209\n",
            "iteration :  50, loss : 0.0004, accuracy : 100.00\n",
            "iteration : 100, loss : 0.0009, accuracy : 99.98\n",
            "iteration : 150, loss : 0.0008, accuracy : 99.98\n",
            "iteration : 200, loss : 0.0008, accuracy : 99.99\n",
            "iteration : 250, loss : 0.0010, accuracy : 99.98\n",
            "iteration : 300, loss : 0.0009, accuracy : 99.98\n",
            "Epoch : 209, training loss : 0.0009, training accuracy : 99.98, val loss : 0.4992, val accuracy : 91.63\n",
            "\n",
            "Epoch: 210\n",
            "iteration :  50, loss : 0.0005, accuracy : 100.00\n",
            "iteration : 100, loss : 0.0006, accuracy : 99.99\n",
            "iteration : 150, loss : 0.0008, accuracy : 99.98\n",
            "iteration : 200, loss : 0.0009, accuracy : 99.97\n",
            "iteration : 250, loss : 0.0010, accuracy : 99.97\n",
            "iteration : 300, loss : 0.0010, accuracy : 99.97\n",
            "Epoch : 210, training loss : 0.0010, training accuracy : 99.97, val loss : 0.5160, val accuracy : 91.65\n",
            "\n",
            "Epoch: 211\n",
            "iteration :  50, loss : 0.0009, accuracy : 99.97\n",
            "iteration : 100, loss : 0.0012, accuracy : 99.95\n",
            "iteration : 150, loss : 0.0015, accuracy : 99.94\n",
            "iteration : 200, loss : 0.0020, accuracy : 99.92\n",
            "iteration : 250, loss : 0.0021, accuracy : 99.92\n",
            "iteration : 300, loss : 0.0019, accuracy : 99.93\n",
            "Epoch : 211, training loss : 0.0018, training accuracy : 99.93, val loss : 0.5391, val accuracy : 91.48\n",
            "\n",
            "Epoch: 212\n",
            "iteration :  50, loss : 0.0011, accuracy : 99.97\n",
            "iteration : 100, loss : 0.0013, accuracy : 99.96\n",
            "iteration : 150, loss : 0.0014, accuracy : 99.95\n",
            "iteration : 200, loss : 0.0013, accuracy : 99.96\n",
            "iteration : 250, loss : 0.0013, accuracy : 99.96\n",
            "iteration : 300, loss : 0.0013, accuracy : 99.96\n",
            "Epoch : 212, training loss : 0.0014, training accuracy : 99.95, val loss : 0.5449, val accuracy : 91.46\n",
            "\n",
            "Epoch: 213\n",
            "iteration :  50, loss : 0.0021, accuracy : 99.91\n",
            "iteration : 100, loss : 0.0022, accuracy : 99.90\n",
            "iteration : 150, loss : 0.0022, accuracy : 99.91\n",
            "iteration : 200, loss : 0.0022, accuracy : 99.90\n",
            "iteration : 250, loss : 0.0021, accuracy : 99.90\n",
            "iteration : 300, loss : 0.0020, accuracy : 99.91\n",
            "Epoch : 213, training loss : 0.0020, training accuracy : 99.91, val loss : 0.5316, val accuracy : 91.43\n",
            "\n",
            "Epoch: 214\n",
            "iteration :  50, loss : 0.0017, accuracy : 99.97\n",
            "iteration : 100, loss : 0.0021, accuracy : 99.95\n",
            "iteration : 150, loss : 0.0017, accuracy : 99.95\n",
            "iteration : 200, loss : 0.0022, accuracy : 99.93\n",
            "iteration : 250, loss : 0.0023, accuracy : 99.92\n",
            "iteration : 300, loss : 0.0025, accuracy : 99.92\n",
            "Epoch : 214, training loss : 0.0026, training accuracy : 99.91, val loss : 0.5513, val accuracy : 91.20\n",
            "\n",
            "Epoch: 215\n",
            "iteration :  50, loss : 0.0039, accuracy : 99.89\n",
            "iteration : 100, loss : 0.0051, accuracy : 99.84\n",
            "iteration : 150, loss : 0.0047, accuracy : 99.85\n",
            "iteration : 200, loss : 0.0040, accuracy : 99.88\n",
            "iteration : 250, loss : 0.0037, accuracy : 99.89\n",
            "iteration : 300, loss : 0.0033, accuracy : 99.90\n",
            "Epoch : 215, training loss : 0.0031, training accuracy : 99.91, val loss : 0.5468, val accuracy : 91.80\n",
            "\n",
            "Epoch: 216\n",
            "iteration :  50, loss : 0.0043, accuracy : 99.88\n",
            "iteration : 100, loss : 0.0034, accuracy : 99.89\n",
            "iteration : 150, loss : 0.0031, accuracy : 99.89\n",
            "iteration : 200, loss : 0.0028, accuracy : 99.90\n",
            "iteration : 250, loss : 0.0032, accuracy : 99.89\n",
            "iteration : 300, loss : 0.0031, accuracy : 99.90\n",
            "Epoch : 216, training loss : 0.0031, training accuracy : 99.90, val loss : 0.5166, val accuracy : 91.55\n",
            "\n",
            "Epoch: 217\n",
            "iteration :  50, loss : 0.0018, accuracy : 99.94\n",
            "iteration : 100, loss : 0.0031, accuracy : 99.92\n",
            "iteration : 150, loss : 0.0027, accuracy : 99.92\n",
            "iteration : 200, loss : 0.0025, accuracy : 99.93\n",
            "iteration : 250, loss : 0.0025, accuracy : 99.93\n",
            "iteration : 300, loss : 0.0023, accuracy : 99.93\n",
            "Epoch : 217, training loss : 0.0023, training accuracy : 99.94, val loss : 0.5168, val accuracy : 91.59\n",
            "\n",
            "Epoch: 218\n",
            "iteration :  50, loss : 0.0007, accuracy : 99.98\n",
            "iteration : 100, loss : 0.0008, accuracy : 99.97\n",
            "iteration : 150, loss : 0.0008, accuracy : 99.97\n",
            "iteration : 200, loss : 0.0009, accuracy : 99.96\n",
            "iteration : 250, loss : 0.0014, accuracy : 99.96\n",
            "iteration : 300, loss : 0.0015, accuracy : 99.95\n",
            "Epoch : 218, training loss : 0.0016, training accuracy : 99.95, val loss : 0.5534, val accuracy : 91.46\n",
            "\n",
            "Epoch: 219\n",
            "iteration :  50, loss : 0.0033, accuracy : 99.88\n",
            "iteration : 100, loss : 0.0032, accuracy : 99.88\n",
            "iteration : 150, loss : 0.0036, accuracy : 99.88\n",
            "iteration : 200, loss : 0.0036, accuracy : 99.88\n",
            "iteration : 250, loss : 0.0038, accuracy : 99.87\n",
            "iteration : 300, loss : 0.0035, accuracy : 99.88\n",
            "Epoch : 219, training loss : 0.0034, training accuracy : 99.89, val loss : 0.5675, val accuracy : 91.14\n",
            "\n",
            "Epoch: 220\n",
            "iteration :  50, loss : 0.0024, accuracy : 99.89\n",
            "iteration : 100, loss : 0.0033, accuracy : 99.88\n",
            "iteration : 150, loss : 0.0027, accuracy : 99.92\n",
            "iteration : 200, loss : 0.0033, accuracy : 99.90\n",
            "iteration : 250, loss : 0.0036, accuracy : 99.89\n",
            "iteration : 300, loss : 0.0038, accuracy : 99.88\n",
            "Epoch : 220, training loss : 0.0038, training accuracy : 99.88, val loss : 0.5695, val accuracy : 91.16\n",
            "\n",
            "Epoch: 221\n",
            "iteration :  50, loss : 0.0048, accuracy : 99.86\n",
            "iteration : 100, loss : 0.0043, accuracy : 99.89\n",
            "iteration : 150, loss : 0.0037, accuracy : 99.90\n",
            "iteration : 200, loss : 0.0038, accuracy : 99.90\n",
            "iteration : 250, loss : 0.0039, accuracy : 99.89\n",
            "iteration : 300, loss : 0.0035, accuracy : 99.90\n",
            "Epoch : 221, training loss : 0.0036, training accuracy : 99.90, val loss : 0.5527, val accuracy : 91.32\n",
            "\n",
            "Epoch: 222\n",
            "iteration :  50, loss : 0.0022, accuracy : 99.97\n",
            "iteration : 100, loss : 0.0016, accuracy : 99.98\n",
            "iteration : 150, loss : 0.0019, accuracy : 99.95\n",
            "iteration : 200, loss : 0.0021, accuracy : 99.93\n",
            "iteration : 250, loss : 0.0028, accuracy : 99.89\n",
            "iteration : 300, loss : 0.0033, accuracy : 99.88\n",
            "Epoch : 222, training loss : 0.0034, training accuracy : 99.88, val loss : 0.5650, val accuracy : 91.21\n",
            "\n",
            "Epoch: 223\n",
            "iteration :  50, loss : 0.0035, accuracy : 99.89\n",
            "iteration : 100, loss : 0.0037, accuracy : 99.90\n",
            "iteration : 150, loss : 0.0030, accuracy : 99.91\n",
            "iteration : 200, loss : 0.0027, accuracy : 99.91\n",
            "iteration : 250, loss : 0.0026, accuracy : 99.92\n",
            "iteration : 300, loss : 0.0025, accuracy : 99.92\n",
            "Epoch : 223, training loss : 0.0025, training accuracy : 99.92, val loss : 0.5378, val accuracy : 91.47\n",
            "\n",
            "Epoch: 224\n",
            "iteration :  50, loss : 0.0018, accuracy : 99.94\n",
            "iteration : 100, loss : 0.0026, accuracy : 99.91\n",
            "iteration : 150, loss : 0.0032, accuracy : 99.89\n",
            "iteration : 200, loss : 0.0032, accuracy : 99.89\n",
            "iteration : 250, loss : 0.0033, accuracy : 99.88\n",
            "iteration : 300, loss : 0.0034, accuracy : 99.88\n",
            "Epoch : 224, training loss : 0.0033, training accuracy : 99.88, val loss : 0.5477, val accuracy : 91.16\n",
            "\n",
            "Epoch: 225\n",
            "iteration :  50, loss : 0.0024, accuracy : 99.91\n",
            "iteration : 100, loss : 0.0025, accuracy : 99.91\n",
            "iteration : 150, loss : 0.0021, accuracy : 99.92\n",
            "iteration : 200, loss : 0.0027, accuracy : 99.89\n",
            "iteration : 250, loss : 0.0032, accuracy : 99.89\n",
            "iteration : 300, loss : 0.0031, accuracy : 99.90\n",
            "Epoch : 225, training loss : 0.0030, training accuracy : 99.90, val loss : 0.5173, val accuracy : 91.81\n",
            "\n",
            "Epoch: 226\n",
            "iteration :  50, loss : 0.0019, accuracy : 99.94\n",
            "iteration : 100, loss : 0.0018, accuracy : 99.95\n",
            "iteration : 150, loss : 0.0019, accuracy : 99.93\n",
            "iteration : 200, loss : 0.0020, accuracy : 99.93\n",
            "iteration : 250, loss : 0.0023, accuracy : 99.92\n",
            "iteration : 300, loss : 0.0021, accuracy : 99.93\n",
            "Epoch : 226, training loss : 0.0021, training accuracy : 99.94, val loss : 0.5307, val accuracy : 91.50\n",
            "\n",
            "Epoch: 227\n",
            "iteration :  50, loss : 0.0020, accuracy : 99.92\n",
            "iteration : 100, loss : 0.0020, accuracy : 99.95\n",
            "iteration : 150, loss : 0.0025, accuracy : 99.92\n",
            "iteration : 200, loss : 0.0024, accuracy : 99.92\n",
            "iteration : 250, loss : 0.0025, accuracy : 99.92\n",
            "iteration : 300, loss : 0.0025, accuracy : 99.91\n",
            "Epoch : 227, training loss : 0.0024, training accuracy : 99.92, val loss : 0.5429, val accuracy : 91.59\n",
            "\n",
            "Epoch: 228\n",
            "iteration :  50, loss : 0.0025, accuracy : 99.94\n",
            "iteration : 100, loss : 0.0019, accuracy : 99.95\n",
            "iteration : 150, loss : 0.0017, accuracy : 99.96\n",
            "iteration : 200, loss : 0.0019, accuracy : 99.95\n",
            "iteration : 250, loss : 0.0018, accuracy : 99.96\n",
            "iteration : 300, loss : 0.0016, accuracy : 99.96\n",
            "Epoch : 228, training loss : 0.0016, training accuracy : 99.96, val loss : 0.5173, val accuracy : 91.64\n",
            "\n",
            "Epoch: 229\n",
            "iteration :  50, loss : 0.0009, accuracy : 99.97\n",
            "iteration : 100, loss : 0.0011, accuracy : 99.95\n",
            "iteration : 150, loss : 0.0012, accuracy : 99.96\n",
            "iteration : 200, loss : 0.0012, accuracy : 99.96\n",
            "iteration : 250, loss : 0.0012, accuracy : 99.96\n",
            "iteration : 300, loss : 0.0013, accuracy : 99.96\n",
            "Epoch : 229, training loss : 0.0012, training accuracy : 99.97, val loss : 0.5159, val accuracy : 92.03\n",
            "\n",
            "Epoch: 230\n",
            "iteration :  50, loss : 0.0005, accuracy : 100.00\n",
            "iteration : 100, loss : 0.0006, accuracy : 99.98\n",
            "iteration : 150, loss : 0.0006, accuracy : 99.99\n",
            "iteration : 200, loss : 0.0009, accuracy : 99.98\n",
            "iteration : 250, loss : 0.0012, accuracy : 99.97\n",
            "iteration : 300, loss : 0.0014, accuracy : 99.96\n",
            "Epoch : 230, training loss : 0.0014, training accuracy : 99.96, val loss : 0.5281, val accuracy : 91.56\n",
            "\n",
            "Epoch: 231\n",
            "iteration :  50, loss : 0.0028, accuracy : 99.92\n",
            "iteration : 100, loss : 0.0023, accuracy : 99.94\n",
            "iteration : 150, loss : 0.0018, accuracy : 99.95\n",
            "iteration : 200, loss : 0.0019, accuracy : 99.94\n",
            "iteration : 250, loss : 0.0022, accuracy : 99.93\n",
            "iteration : 300, loss : 0.0022, accuracy : 99.92\n",
            "Epoch : 231, training loss : 0.0022, training accuracy : 99.92, val loss : 0.5352, val accuracy : 91.99\n",
            "\n",
            "Epoch: 232\n",
            "iteration :  50, loss : 0.0023, accuracy : 99.92\n",
            "iteration : 100, loss : 0.0017, accuracy : 99.95\n",
            "iteration : 150, loss : 0.0021, accuracy : 99.93\n",
            "iteration : 200, loss : 0.0018, accuracy : 99.95\n",
            "iteration : 250, loss : 0.0018, accuracy : 99.94\n",
            "iteration : 300, loss : 0.0019, accuracy : 99.95\n",
            "Epoch : 232, training loss : 0.0019, training accuracy : 99.95, val loss : 0.5453, val accuracy : 91.58\n",
            "\n",
            "Epoch: 233\n",
            "iteration :  50, loss : 0.0011, accuracy : 99.97\n",
            "iteration : 100, loss : 0.0011, accuracy : 99.97\n",
            "iteration : 150, loss : 0.0010, accuracy : 99.97\n",
            "iteration : 200, loss : 0.0010, accuracy : 99.98\n",
            "iteration : 250, loss : 0.0010, accuracy : 99.97\n",
            "iteration : 300, loss : 0.0009, accuracy : 99.98\n",
            "Epoch : 233, training loss : 0.0009, training accuracy : 99.98, val loss : 0.5133, val accuracy : 91.82\n",
            "\n",
            "Epoch: 234\n",
            "iteration :  50, loss : 0.0016, accuracy : 99.94\n",
            "iteration : 100, loss : 0.0011, accuracy : 99.96\n",
            "iteration : 150, loss : 0.0010, accuracy : 99.97\n",
            "iteration : 200, loss : 0.0010, accuracy : 99.97\n",
            "iteration : 250, loss : 0.0010, accuracy : 99.97\n",
            "iteration : 300, loss : 0.0011, accuracy : 99.97\n",
            "Epoch : 234, training loss : 0.0011, training accuracy : 99.97, val loss : 0.5118, val accuracy : 92.03\n",
            "\n",
            "Epoch: 235\n",
            "iteration :  50, loss : 0.0017, accuracy : 99.97\n",
            "iteration : 100, loss : 0.0020, accuracy : 99.97\n",
            "iteration : 150, loss : 0.0021, accuracy : 99.94\n",
            "iteration : 200, loss : 0.0020, accuracy : 99.95\n",
            "iteration : 250, loss : 0.0020, accuracy : 99.94\n",
            "iteration : 300, loss : 0.0021, accuracy : 99.94\n",
            "Epoch : 235, training loss : 0.0021, training accuracy : 99.94, val loss : 0.5032, val accuracy : 91.77\n",
            "\n",
            "Epoch: 236\n",
            "iteration :  50, loss : 0.0024, accuracy : 99.94\n",
            "iteration : 100, loss : 0.0020, accuracy : 99.95\n",
            "iteration : 150, loss : 0.0020, accuracy : 99.94\n",
            "iteration : 200, loss : 0.0023, accuracy : 99.93\n",
            "iteration : 250, loss : 0.0020, accuracy : 99.93\n",
            "iteration : 300, loss : 0.0020, accuracy : 99.94\n",
            "Epoch : 236, training loss : 0.0020, training accuracy : 99.94, val loss : 0.5570, val accuracy : 91.44\n",
            "\n",
            "Epoch: 237\n",
            "iteration :  50, loss : 0.0014, accuracy : 99.97\n",
            "iteration : 100, loss : 0.0019, accuracy : 99.95\n",
            "iteration : 150, loss : 0.0023, accuracy : 99.93\n",
            "iteration : 200, loss : 0.0023, accuracy : 99.93\n",
            "iteration : 250, loss : 0.0025, accuracy : 99.92\n",
            "iteration : 300, loss : 0.0026, accuracy : 99.92\n",
            "Epoch : 237, training loss : 0.0026, training accuracy : 99.92, val loss : 0.5494, val accuracy : 91.66\n",
            "\n",
            "Epoch: 238\n",
            "iteration :  50, loss : 0.0021, accuracy : 99.92\n",
            "iteration : 100, loss : 0.0035, accuracy : 99.91\n",
            "iteration : 150, loss : 0.0039, accuracy : 99.88\n",
            "iteration : 200, loss : 0.0033, accuracy : 99.89\n",
            "iteration : 250, loss : 0.0031, accuracy : 99.90\n",
            "iteration : 300, loss : 0.0030, accuracy : 99.90\n",
            "Epoch : 238, training loss : 0.0029, training accuracy : 99.90, val loss : 0.5544, val accuracy : 91.54\n",
            "\n",
            "Epoch: 239\n",
            "iteration :  50, loss : 0.0009, accuracy : 100.00\n",
            "iteration : 100, loss : 0.0011, accuracy : 99.98\n",
            "iteration : 150, loss : 0.0012, accuracy : 99.97\n",
            "iteration : 200, loss : 0.0011, accuracy : 99.98\n",
            "iteration : 250, loss : 0.0012, accuracy : 99.97\n",
            "iteration : 300, loss : 0.0013, accuracy : 99.97\n",
            "Epoch : 239, training loss : 0.0012, training accuracy : 99.97, val loss : 0.5586, val accuracy : 91.67\n",
            "\n",
            "Epoch: 240\n",
            "iteration :  50, loss : 0.0022, accuracy : 99.94\n",
            "iteration : 100, loss : 0.0022, accuracy : 99.91\n",
            "iteration : 150, loss : 0.0018, accuracy : 99.93\n",
            "iteration : 200, loss : 0.0022, accuracy : 99.92\n",
            "iteration : 250, loss : 0.0020, accuracy : 99.93\n",
            "iteration : 300, loss : 0.0019, accuracy : 99.93\n",
            "Epoch : 240, training loss : 0.0019, training accuracy : 99.94, val loss : 0.5431, val accuracy : 91.69\n",
            "\n",
            "Epoch: 241\n",
            "iteration :  50, loss : 0.0013, accuracy : 99.95\n",
            "iteration : 100, loss : 0.0012, accuracy : 99.95\n",
            "iteration : 150, loss : 0.0012, accuracy : 99.94\n",
            "iteration : 200, loss : 0.0011, accuracy : 99.95\n",
            "iteration : 250, loss : 0.0012, accuracy : 99.95\n",
            "iteration : 300, loss : 0.0012, accuracy : 99.95\n",
            "Epoch : 241, training loss : 0.0012, training accuracy : 99.95, val loss : 0.5306, val accuracy : 91.67\n",
            "\n",
            "Epoch: 242\n",
            "iteration :  50, loss : 0.0025, accuracy : 99.92\n",
            "iteration : 100, loss : 0.0016, accuracy : 99.95\n",
            "iteration : 150, loss : 0.0015, accuracy : 99.95\n",
            "iteration : 200, loss : 0.0021, accuracy : 99.93\n",
            "iteration : 250, loss : 0.0025, accuracy : 99.92\n",
            "iteration : 300, loss : 0.0026, accuracy : 99.92\n",
            "Epoch : 242, training loss : 0.0026, training accuracy : 99.92, val loss : 0.5552, val accuracy : 91.41\n",
            "\n",
            "Epoch: 243\n",
            "iteration :  50, loss : 0.0015, accuracy : 99.97\n",
            "iteration : 100, loss : 0.0024, accuracy : 99.91\n",
            "iteration : 150, loss : 0.0022, accuracy : 99.92\n",
            "iteration : 200, loss : 0.0025, accuracy : 99.92\n",
            "iteration : 250, loss : 0.0034, accuracy : 99.88\n",
            "iteration : 300, loss : 0.0037, accuracy : 99.88\n",
            "Epoch : 243, training loss : 0.0038, training accuracy : 99.87, val loss : 0.5478, val accuracy : 91.43\n",
            "\n",
            "Epoch: 244\n",
            "iteration :  50, loss : 0.0032, accuracy : 99.92\n",
            "iteration : 100, loss : 0.0032, accuracy : 99.91\n",
            "iteration : 150, loss : 0.0031, accuracy : 99.91\n",
            "iteration : 200, loss : 0.0029, accuracy : 99.92\n",
            "iteration : 250, loss : 0.0031, accuracy : 99.91\n",
            "iteration : 300, loss : 0.0028, accuracy : 99.91\n",
            "Epoch : 244, training loss : 0.0028, training accuracy : 99.92, val loss : 0.5503, val accuracy : 90.94\n",
            "\n",
            "Epoch: 245\n",
            "iteration :  50, loss : 0.0038, accuracy : 99.86\n",
            "iteration : 100, loss : 0.0036, accuracy : 99.83\n",
            "iteration : 150, loss : 0.0032, accuracy : 99.85\n",
            "iteration : 200, loss : 0.0033, accuracy : 99.85\n",
            "iteration : 250, loss : 0.0031, accuracy : 99.86\n",
            "iteration : 300, loss : 0.0029, accuracy : 99.87\n",
            "Epoch : 245, training loss : 0.0029, training accuracy : 99.88, val loss : 0.5564, val accuracy : 91.41\n",
            "\n",
            "Epoch: 246\n",
            "iteration :  50, loss : 0.0019, accuracy : 99.94\n",
            "iteration : 100, loss : 0.0020, accuracy : 99.92\n",
            "iteration : 150, loss : 0.0021, accuracy : 99.91\n",
            "iteration : 200, loss : 0.0022, accuracy : 99.89\n",
            "iteration : 250, loss : 0.0023, accuracy : 99.89\n",
            "iteration : 300, loss : 0.0024, accuracy : 99.89\n",
            "Epoch : 246, training loss : 0.0025, training accuracy : 99.89, val loss : 0.5540, val accuracy : 91.66\n",
            "\n",
            "Epoch: 247\n",
            "iteration :  50, loss : 0.0010, accuracy : 100.00\n",
            "iteration : 100, loss : 0.0013, accuracy : 99.98\n",
            "iteration : 150, loss : 0.0011, accuracy : 99.98\n",
            "iteration : 200, loss : 0.0012, accuracy : 99.98\n",
            "iteration : 250, loss : 0.0011, accuracy : 99.98\n",
            "iteration : 300, loss : 0.0012, accuracy : 99.97\n",
            "Epoch : 247, training loss : 0.0012, training accuracy : 99.97, val loss : 0.5523, val accuracy : 91.66\n",
            "\n",
            "Epoch: 248\n",
            "iteration :  50, loss : 0.0012, accuracy : 99.95\n",
            "iteration : 100, loss : 0.0011, accuracy : 99.97\n",
            "iteration : 150, loss : 0.0011, accuracy : 99.97\n",
            "iteration : 200, loss : 0.0010, accuracy : 99.97\n",
            "iteration : 250, loss : 0.0009, accuracy : 99.97\n",
            "iteration : 300, loss : 0.0009, accuracy : 99.98\n",
            "Epoch : 248, training loss : 0.0008, training accuracy : 99.98, val loss : 0.5331, val accuracy : 91.78\n",
            "\n",
            "Epoch: 249\n",
            "iteration :  50, loss : 0.0014, accuracy : 99.95\n",
            "iteration : 100, loss : 0.0010, accuracy : 99.96\n",
            "iteration : 150, loss : 0.0011, accuracy : 99.96\n",
            "iteration : 200, loss : 0.0012, accuracy : 99.96\n",
            "iteration : 250, loss : 0.0010, accuracy : 99.97\n",
            "iteration : 300, loss : 0.0009, accuracy : 99.97\n",
            "Epoch : 249, training loss : 0.0009, training accuracy : 99.97, val loss : 0.5212, val accuracy : 91.85\n",
            "\n",
            "Epoch: 250\n",
            "iteration :  50, loss : 0.0005, accuracy : 100.00\n",
            "iteration : 100, loss : 0.0008, accuracy : 99.98\n",
            "iteration : 150, loss : 0.0009, accuracy : 99.97\n",
            "iteration : 200, loss : 0.0010, accuracy : 99.97\n",
            "iteration : 250, loss : 0.0009, accuracy : 99.98\n",
            "iteration : 300, loss : 0.0010, accuracy : 99.97\n",
            "Epoch : 250, training loss : 0.0010, training accuracy : 99.97, val loss : 0.5523, val accuracy : 91.74\n",
            "\n",
            "Epoch: 251\n",
            "iteration :  50, loss : 0.0009, accuracy : 99.98\n",
            "iteration : 100, loss : 0.0010, accuracy : 99.98\n",
            "iteration : 150, loss : 0.0010, accuracy : 99.97\n",
            "iteration : 200, loss : 0.0009, accuracy : 99.97\n",
            "iteration : 250, loss : 0.0009, accuracy : 99.97\n",
            "iteration : 300, loss : 0.0009, accuracy : 99.98\n",
            "Epoch : 251, training loss : 0.0009, training accuracy : 99.98, val loss : 0.5335, val accuracy : 91.95\n",
            "\n",
            "Epoch: 252\n",
            "iteration :  50, loss : 0.0006, accuracy : 99.98\n",
            "iteration : 100, loss : 0.0007, accuracy : 99.98\n",
            "iteration : 150, loss : 0.0007, accuracy : 99.98\n",
            "iteration : 200, loss : 0.0007, accuracy : 99.98\n",
            "iteration : 250, loss : 0.0007, accuracy : 99.98\n",
            "iteration : 300, loss : 0.0006, accuracy : 99.98\n",
            "Epoch : 252, training loss : 0.0006, training accuracy : 99.98, val loss : 0.5264, val accuracy : 91.88\n",
            "\n",
            "Epoch: 253\n",
            "iteration :  50, loss : 0.0009, accuracy : 99.95\n",
            "iteration : 100, loss : 0.0006, accuracy : 99.98\n",
            "iteration : 150, loss : 0.0005, accuracy : 99.98\n",
            "iteration : 200, loss : 0.0005, accuracy : 99.98\n",
            "iteration : 250, loss : 0.0004, accuracy : 99.99\n",
            "iteration : 300, loss : 0.0004, accuracy : 99.99\n",
            "Epoch : 253, training loss : 0.0004, training accuracy : 99.99, val loss : 0.5154, val accuracy : 92.00\n",
            "\n",
            "Epoch: 254\n",
            "iteration :  50, loss : 0.0004, accuracy : 100.00\n",
            "iteration : 100, loss : 0.0004, accuracy : 100.00\n",
            "iteration : 150, loss : 0.0003, accuracy : 100.00\n",
            "iteration : 200, loss : 0.0003, accuracy : 100.00\n",
            "iteration : 250, loss : 0.0003, accuracy : 100.00\n",
            "iteration : 300, loss : 0.0003, accuracy : 99.99\n",
            "Epoch : 254, training loss : 0.0003, training accuracy : 99.99, val loss : 0.5168, val accuracy : 92.11\n",
            "\n",
            "Epoch: 255\n",
            "iteration :  50, loss : 0.0004, accuracy : 100.00\n",
            "iteration : 100, loss : 0.0005, accuracy : 99.98\n",
            "iteration : 150, loss : 0.0005, accuracy : 99.99\n",
            "iteration : 200, loss : 0.0005, accuracy : 99.99\n",
            "iteration : 250, loss : 0.0005, accuracy : 99.99\n",
            "iteration : 300, loss : 0.0005, accuracy : 99.98\n",
            "Epoch : 255, training loss : 0.0005, training accuracy : 99.98, val loss : 0.5155, val accuracy : 91.95\n",
            "\n",
            "Epoch: 256\n",
            "iteration :  50, loss : 0.0012, accuracy : 99.98\n",
            "iteration : 100, loss : 0.0012, accuracy : 99.98\n",
            "iteration : 150, loss : 0.0011, accuracy : 99.97\n",
            "iteration : 200, loss : 0.0012, accuracy : 99.96\n",
            "iteration : 250, loss : 0.0012, accuracy : 99.96\n",
            "iteration : 300, loss : 0.0011, accuracy : 99.97\n",
            "Epoch : 256, training loss : 0.0011, training accuracy : 99.97, val loss : 0.5440, val accuracy : 91.55\n",
            "\n",
            "Epoch: 257\n",
            "iteration :  50, loss : 0.0008, accuracy : 99.98\n",
            "iteration : 100, loss : 0.0017, accuracy : 99.96\n",
            "iteration : 150, loss : 0.0015, accuracy : 99.97\n",
            "iteration : 200, loss : 0.0013, accuracy : 99.97\n",
            "iteration : 250, loss : 0.0010, accuracy : 99.98\n",
            "iteration : 300, loss : 0.0010, accuracy : 99.98\n",
            "Epoch : 257, training loss : 0.0010, training accuracy : 99.98, val loss : 0.5500, val accuracy : 91.99\n",
            "\n",
            "Epoch: 258\n",
            "iteration :  50, loss : 0.0006, accuracy : 99.97\n",
            "iteration : 100, loss : 0.0005, accuracy : 99.98\n",
            "iteration : 150, loss : 0.0006, accuracy : 99.97\n",
            "iteration : 200, loss : 0.0006, accuracy : 99.97\n",
            "iteration : 250, loss : 0.0006, accuracy : 99.98\n",
            "iteration : 300, loss : 0.0007, accuracy : 99.98\n",
            "Epoch : 258, training loss : 0.0008, training accuracy : 99.98, val loss : 0.5469, val accuracy : 92.08\n",
            "\n",
            "Epoch: 259\n",
            "iteration :  50, loss : 0.0008, accuracy : 99.98\n",
            "iteration : 100, loss : 0.0008, accuracy : 99.98\n",
            "iteration : 150, loss : 0.0006, accuracy : 99.99\n",
            "iteration : 200, loss : 0.0007, accuracy : 99.98\n",
            "iteration : 250, loss : 0.0008, accuracy : 99.97\n",
            "iteration : 300, loss : 0.0007, accuracy : 99.98\n",
            "Epoch : 259, training loss : 0.0007, training accuracy : 99.98, val loss : 0.5539, val accuracy : 91.79\n",
            "\n",
            "Epoch: 260\n",
            "iteration :  50, loss : 0.0006, accuracy : 99.98\n",
            "iteration : 100, loss : 0.0007, accuracy : 99.98\n",
            "iteration : 150, loss : 0.0008, accuracy : 99.97\n",
            "iteration : 200, loss : 0.0010, accuracy : 99.97\n",
            "iteration : 250, loss : 0.0010, accuracy : 99.97\n",
            "iteration : 300, loss : 0.0010, accuracy : 99.97\n",
            "Epoch : 260, training loss : 0.0010, training accuracy : 99.97, val loss : 0.5529, val accuracy : 91.53\n",
            "\n",
            "Epoch: 261\n",
            "iteration :  50, loss : 0.0010, accuracy : 99.95\n",
            "iteration : 100, loss : 0.0009, accuracy : 99.97\n",
            "iteration : 150, loss : 0.0008, accuracy : 99.97\n",
            "iteration : 200, loss : 0.0008, accuracy : 99.98\n",
            "iteration : 250, loss : 0.0007, accuracy : 99.98\n",
            "iteration : 300, loss : 0.0007, accuracy : 99.98\n",
            "Epoch : 261, training loss : 0.0007, training accuracy : 99.98, val loss : 0.5365, val accuracy : 92.09\n",
            "\n",
            "Epoch: 262\n",
            "iteration :  50, loss : 0.0003, accuracy : 100.00\n",
            "iteration : 100, loss : 0.0004, accuracy : 99.99\n",
            "iteration : 150, loss : 0.0004, accuracy : 99.99\n",
            "iteration : 200, loss : 0.0005, accuracy : 99.98\n",
            "iteration : 250, loss : 0.0005, accuracy : 99.98\n",
            "iteration : 300, loss : 0.0005, accuracy : 99.99\n",
            "Epoch : 262, training loss : 0.0005, training accuracy : 99.99, val loss : 0.5236, val accuracy : 92.06\n",
            "\n",
            "Epoch: 263\n",
            "iteration :  50, loss : 0.0007, accuracy : 99.98\n",
            "iteration : 100, loss : 0.0005, accuracy : 99.99\n",
            "iteration : 150, loss : 0.0007, accuracy : 99.98\n",
            "iteration : 200, loss : 0.0007, accuracy : 99.98\n",
            "iteration : 250, loss : 0.0007, accuracy : 99.98\n",
            "iteration : 300, loss : 0.0007, accuracy : 99.98\n",
            "Epoch : 263, training loss : 0.0007, training accuracy : 99.98, val loss : 0.5500, val accuracy : 91.84\n",
            "\n",
            "Epoch: 264\n",
            "iteration :  50, loss : 0.0004, accuracy : 99.98\n",
            "iteration : 100, loss : 0.0009, accuracy : 99.98\n",
            "iteration : 150, loss : 0.0012, accuracy : 99.97\n",
            "iteration : 200, loss : 0.0013, accuracy : 99.96\n",
            "iteration : 250, loss : 0.0013, accuracy : 99.97\n",
            "iteration : 300, loss : 0.0013, accuracy : 99.96\n",
            "Epoch : 264, training loss : 0.0013, training accuracy : 99.97, val loss : 0.5341, val accuracy : 91.73\n",
            "\n",
            "Epoch: 265\n",
            "iteration :  50, loss : 0.0020, accuracy : 99.94\n",
            "iteration : 100, loss : 0.0025, accuracy : 99.92\n",
            "iteration : 150, loss : 0.0025, accuracy : 99.91\n",
            "iteration : 200, loss : 0.0021, accuracy : 99.93\n",
            "iteration : 250, loss : 0.0020, accuracy : 99.93\n",
            "iteration : 300, loss : 0.0018, accuracy : 99.94\n",
            "Epoch : 265, training loss : 0.0018, training accuracy : 99.94, val loss : 0.5497, val accuracy : 91.51\n",
            "\n",
            "Epoch: 266\n",
            "iteration :  50, loss : 0.0005, accuracy : 100.00\n",
            "iteration : 100, loss : 0.0005, accuracy : 100.00\n",
            "iteration : 150, loss : 0.0006, accuracy : 99.99\n",
            "iteration : 200, loss : 0.0006, accuracy : 99.99\n",
            "iteration : 250, loss : 0.0008, accuracy : 99.98\n",
            "iteration : 300, loss : 0.0008, accuracy : 99.98\n",
            "Epoch : 266, training loss : 0.0008, training accuracy : 99.98, val loss : 0.5181, val accuracy : 92.06\n",
            "\n",
            "Epoch: 267\n",
            "iteration :  50, loss : 0.0014, accuracy : 99.95\n",
            "iteration : 100, loss : 0.0014, accuracy : 99.95\n",
            "iteration : 150, loss : 0.0016, accuracy : 99.96\n",
            "iteration : 200, loss : 0.0015, accuracy : 99.96\n",
            "iteration : 250, loss : 0.0013, accuracy : 99.97\n",
            "iteration : 300, loss : 0.0012, accuracy : 99.97\n",
            "Epoch : 267, training loss : 0.0012, training accuracy : 99.97, val loss : 0.5442, val accuracy : 91.83\n",
            "\n",
            "Epoch: 268\n",
            "iteration :  50, loss : 0.0004, accuracy : 100.00\n",
            "iteration : 100, loss : 0.0004, accuracy : 100.00\n",
            "iteration : 150, loss : 0.0004, accuracy : 99.99\n",
            "iteration : 200, loss : 0.0004, accuracy : 100.00\n",
            "iteration : 250, loss : 0.0005, accuracy : 99.99\n",
            "iteration : 300, loss : 0.0007, accuracy : 99.98\n",
            "Epoch : 268, training loss : 0.0008, training accuracy : 99.98, val loss : 0.5640, val accuracy : 91.66\n",
            "\n",
            "Epoch: 269\n",
            "iteration :  50, loss : 0.0022, accuracy : 99.94\n",
            "iteration : 100, loss : 0.0018, accuracy : 99.95\n",
            "iteration : 150, loss : 0.0015, accuracy : 99.95\n",
            "iteration : 200, loss : 0.0012, accuracy : 99.96\n",
            "iteration : 250, loss : 0.0011, accuracy : 99.97\n",
            "iteration : 300, loss : 0.0010, accuracy : 99.97\n",
            "Epoch : 269, training loss : 0.0010, training accuracy : 99.97, val loss : 0.5359, val accuracy : 91.77\n",
            "\n",
            "Epoch: 270\n",
            "iteration :  50, loss : 0.0009, accuracy : 99.95\n",
            "iteration : 100, loss : 0.0007, accuracy : 99.97\n",
            "iteration : 150, loss : 0.0007, accuracy : 99.97\n",
            "iteration : 200, loss : 0.0007, accuracy : 99.97\n",
            "iteration : 250, loss : 0.0006, accuracy : 99.98\n",
            "iteration : 300, loss : 0.0006, accuracy : 99.98\n",
            "Epoch : 270, training loss : 0.0006, training accuracy : 99.98, val loss : 0.5308, val accuracy : 92.02\n",
            "\n",
            "Epoch: 271\n",
            "iteration :  50, loss : 0.0019, accuracy : 99.95\n",
            "iteration : 100, loss : 0.0012, accuracy : 99.97\n",
            "iteration : 150, loss : 0.0010, accuracy : 99.97\n",
            "iteration : 200, loss : 0.0008, accuracy : 99.98\n",
            "iteration : 250, loss : 0.0007, accuracy : 99.98\n",
            "iteration : 300, loss : 0.0006, accuracy : 99.99\n",
            "Epoch : 271, training loss : 0.0006, training accuracy : 99.99, val loss : 0.5350, val accuracy : 92.19\n",
            "\n",
            "Epoch: 272\n",
            "iteration :  50, loss : 0.0004, accuracy : 99.97\n",
            "iteration : 100, loss : 0.0003, accuracy : 99.98\n",
            "iteration : 150, loss : 0.0004, accuracy : 99.98\n",
            "iteration : 200, loss : 0.0005, accuracy : 99.98\n",
            "iteration : 250, loss : 0.0006, accuracy : 99.97\n",
            "iteration : 300, loss : 0.0005, accuracy : 99.98\n",
            "Epoch : 272, training loss : 0.0005, training accuracy : 99.98, val loss : 0.5367, val accuracy : 91.89\n",
            "\n",
            "Epoch: 273\n",
            "iteration :  50, loss : 0.0006, accuracy : 99.98\n",
            "iteration : 100, loss : 0.0004, accuracy : 99.99\n",
            "iteration : 150, loss : 0.0004, accuracy : 99.99\n",
            "iteration : 200, loss : 0.0005, accuracy : 99.98\n",
            "iteration : 250, loss : 0.0005, accuracy : 99.98\n",
            "iteration : 300, loss : 0.0006, accuracy : 99.98\n",
            "Epoch : 273, training loss : 0.0006, training accuracy : 99.98, val loss : 0.5337, val accuracy : 91.97\n",
            "\n",
            "Epoch: 274\n",
            "iteration :  50, loss : 0.0006, accuracy : 99.98\n",
            "iteration : 100, loss : 0.0005, accuracy : 99.99\n",
            "iteration : 150, loss : 0.0005, accuracy : 99.99\n",
            "iteration : 200, loss : 0.0005, accuracy : 99.99\n",
            "iteration : 250, loss : 0.0006, accuracy : 99.99\n",
            "iteration : 300, loss : 0.0006, accuracy : 99.98\n",
            "Epoch : 274, training loss : 0.0006, training accuracy : 99.98, val loss : 0.5600, val accuracy : 92.13\n",
            "\n",
            "Epoch: 275\n",
            "iteration :  50, loss : 0.0004, accuracy : 100.00\n",
            "iteration : 100, loss : 0.0009, accuracy : 99.98\n",
            "iteration : 150, loss : 0.0007, accuracy : 99.99\n",
            "iteration : 200, loss : 0.0006, accuracy : 99.99\n",
            "iteration : 250, loss : 0.0005, accuracy : 99.99\n",
            "iteration : 300, loss : 0.0005, accuracy : 99.99\n",
            "Epoch : 275, training loss : 0.0005, training accuracy : 99.99, val loss : 0.5405, val accuracy : 92.16\n",
            "\n",
            "Epoch: 276\n",
            "iteration :  50, loss : 0.0007, accuracy : 99.98\n",
            "iteration : 100, loss : 0.0005, accuracy : 99.98\n",
            "iteration : 150, loss : 0.0005, accuracy : 99.98\n",
            "iteration : 200, loss : 0.0005, accuracy : 99.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"Training with CosineAnnealingLR\")\n",
        "print(f\"{'='*60}\\n\")\n",
        "\n",
        "net = ResNet18().to('cuda')\n",
        "criterion = nn.CrossEntropyLoss().to('cuda')\n",
        "optimizer = optim.SGD(net.parameters(), lr=config['lr'],\n",
        "                      momentum=config['momentum'])\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=300)\n",
        "# Lists to store losses and accuracies\n",
        "train_losses = []\n",
        "train_accs = []\n",
        "val_losses = []\n",
        "val_accs = []\n",
        "\n",
        "for epoch in range(1, 301):\n",
        "    train_loss, train_acc = train(epoch, net, criterion, trainloader, scheduler)\n",
        "    val_loss, val_acc = test(epoch, net, criterion, valloader)\n",
        "     # Store values\n",
        "    train_losses.append(train_loss)\n",
        "    train_accs.append(train_acc)\n",
        "    val_losses.append(val_loss)\n",
        "    val_accs.append(val_acc)\n",
        "    print((\"Epoch : %3d, training loss : %0.4f, training accuracy : %2.2f, val loss \" + \\\n",
        "          \": %0.4f, val accuracy : %2.2f\") % (epoch, train_loss, train_acc, val_loss, val_acc))\n",
        "\n",
        "\n",
        "# Plot\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Loss plot\n",
        "ax1.plot(range(1, 301), train_losses, 'b-', label='Train', linewidth=2)\n",
        "ax1.plot(range(1, 301), val_losses, 'r-', label='Validation', linewidth=2)\n",
        "ax1.set_xlabel(\"Epoch\", fontsize=12)\n",
        "ax1.set_ylabel(\"Loss\", fontsize=12)\n",
        "ax1.set_title(f\"Loss vs Epochs (CosineAnnealingLR)\", fontsize=14)\n",
        "ax1.legend(fontsize=11)\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Accuracy plot\n",
        "ax2.plot(range(1, 301), train_accs, 'b-', label='Train', linewidth=2)\n",
        "ax2.plot(range(1, 301), val_accs, 'r-', label='Validation', linewidth=2)\n",
        "ax2.set_xlabel(\"Epoch\", fontsize=12)\n",
        "ax2.set_ylabel(\"Accuracy (%)\", fontsize=12)\n",
        "ax2.set_title(f\"Accuracy vs Epochs (CosineAnnealingLR)\", fontsize=14)\n",
        "ax2.legend(fontsize=11)\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(f'section4_CosineAnnealingLR.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Print final results\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"Final Results for CosineAnnealingLR\")\n",
        "print(f\"  Train Loss: {train_losses[-1]:.4f}, Train Acc: {train_accs[-1]:.2f}%\")\n",
        "print(f\"  Val Loss: {val_losses[-1]:.4f}, Val Acc: {val_accs[-1]:.2f}%\")\n",
        "print(f\"{'='*60}\\n\")\n"
      ],
      "metadata": {
        "id": "yucqf17mZS9B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}